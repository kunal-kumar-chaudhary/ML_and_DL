{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_NLP_in_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8psTlS2YRgxM97ZTF8Eyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1901010019/1901010019.github.io/blob/master/Introduction_to_NLP_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmXLGss-MXgG",
        "outputId": "c1d3d4ba-c5c7-408e-92e4-4c1ed2e83144"
      },
      "source": [
        "# checking if we are using GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-e79fac01-9f84-57fe-583f-a6cc28318622)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA48YHTRKl8H",
        "outputId": "684673a7-ff0c-4839-ed93-78718e9ac285"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 08:14:38--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-23 08:14:38 (50.6 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dR8N-fLMKpX"
      },
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGypRQSeNrVI"
      },
      "source": [
        "## GETTING THE DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW1jzvCmNhoE"
      },
      "source": [
        "we will use kaggle dataset for our this experimentation.\n",
        "https://www.kaggle.com/c/nlp-getting-started/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ii2LkAMh1A",
        "outputId": "0b8397c2-4bf4-473e-af13-41e9d03d6fc1"
      },
      "source": [
        "# getting a text dataset \n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 08:14:40--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 142.250.103.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-08-23 08:14:41 (78.0 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRFnRh1_Np24"
      },
      "source": [
        "unzip_data('nlp_getting_started.zip') # unzipped the dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3UpOLbzOaEq"
      },
      "source": [
        "## VISUALIZING OUR TEXT DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kEHcuyvN_dW"
      },
      "source": [
        "# reading dataset using pandas library\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yjHo8kETPZVF",
        "outputId": "a689dceb-3b74-4162-a26b-dfb73a924f7f"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cP5FzOWHQNcP",
        "outputId": "55966d70-bd5e-44ec-8b94-8dc78b03e4f7"
      },
      "source": [
        "# shuffling training dataset so that our model doesnot learn any unwanted patterns.\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXhT86JXQ2sb",
        "outputId": "fb2c085d-95cb-4540-cf36-4f83939f403b"
      },
      "source": [
        "# how many examples of each class?\n",
        "train_df_shuffled.target.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utf0QoIiRkOx",
        "outputId": "cf12ecb0-2eb5-4dc8-d8fd-f388b736ad46"
      },
      "source": [
        "# how many total samples\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfN199Q1RrfA",
        "outputId": "98611810-0ca9-494b-e3b1-13370a828c32"
      },
      "source": [
        "# visualize the random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) \n",
        "for row in train_df_shuffled[['text','target']][random_index : random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\" )\n",
        "  print(f\"text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1 (real disaster)\n",
            "text:\n",
            "Damage to school bus on 80 in multi car crash #BREAKING \n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "text:\n",
            "@PrablematicLA @Adweek I'm actually currently dressed for a snowstorm...despite being in the middle of a Texas summer. Thanks office A/C.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "text:\n",
            "I liked a @YouTube video http://t.co/z8Cp77lVza Boeing 737 takeoff in snowstorm. HD cockpit view + ATC audio - Episode 18\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "Anti Collision Rear- #technology #cool http://t.co/hK6nQrGedb\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "text:\n",
            "Sign the petition @david_cameron to protect bees instead of toxic chemical companies want to harm them! #savebees  - http://t.co/dB7ft3Yi6d\n",
            "\n",
            "-----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7k3Wi9LVGTb"
      },
      "source": [
        "### split data into training and validation sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQkCdWCgU82m"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5bOrSRXWrTr",
        "outputId": "50faf6d5-fb4b-43c6-c02d-a595341970bc"
      },
      "source": [
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AclI0foWzHG",
        "outputId": "9702bced-6b2b-4920-efc0-ed66e87a5b16"
      },
      "source": [
        "train_sentences"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       ...,\n",
              "       'Near them on the sand half sunk a shattered visage lies... http://t.co/0kCCG1BT06',\n",
              "       \"kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.\",\n",
              "       \"@ScottDPierce @billharris_tv @HarrisGle @Beezersun I'm forfeiting this years fantasy football pool out of fear I may win n get my ass kicked\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAIeaMY8W7v5",
        "outputId": "63638a86-0aa1-4264-ad1a-0889d6a29e1a"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6CzXib4W-SR",
        "outputId": "292bd8f7-3335-4a66-9a1c-e57802f2b99c"
      },
      "source": [
        "val_sentences[0:10] # viewing initial 10 sentences"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "       'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "       'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "       '@camilacabello97 Internally and externally screaming',\n",
              "       'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov',\n",
              "       'Investigators rule catastrophic structural failure resulted in 2014 Virg.. Related Articles: http://t.co/Cy1LFeNyV8',\n",
              "       'How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd',\n",
              "       \"Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by S\\x89Û_ http://t.co/JDVSGVhlIs\",\n",
              "       '\\x89Ûª93 blasts accused Yeda Yakub dies in Karachi of heart attack http://t.co/mfKqyxd8XG #Mumbai',\n",
              "       'My ears are bleeding  https://t.co/k5KnNwugwT'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04nRtvb9XBMW",
        "outputId": "5725a5db-9093-45a9-abcc-b7b5773e5591"
      },
      "source": [
        "val_labels[0:30] # viewing initial 30 labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhQ9LcFibHJI"
      },
      "source": [
        "## CONVERTING TEXT TO NUMBERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rauLtQa3bFdM"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIRGNV6QbUfP"
      },
      "source": [
        "# # use the default text vectorization parameters\n",
        "# text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabluary\n",
        "#                                     standardize='lower_and_strip_punctuation',\n",
        "#                                     split='whitespace',\n",
        "#                                     ngrams=None,\n",
        "#                                     output_mode='int',\n",
        "#                                     output_sequence_length=None,\n",
        "#                                     pad_to_max_tokens=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZypZpsvBeDaU",
        "outputId": "b939a818-ce99-4afd-c19c-a0f4c9c47b29"
      },
      "source": [
        "# find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
        "# so there are 15 words in every tweet on average"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAzw35o4fjDg"
      },
      "source": [
        "# setup text vectorization variables\n",
        "max_vocab_length = 10000 # maximum number of words to have in our dictionary\n",
        "max_length = 15 # max length our sequence will be\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAhCEPJwhZ8S"
      },
      "source": [
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M22C-2skhrrC",
        "outputId": "7837a111-5ad3-4db7-9c57-d83a444c3c27"
      },
      "source": [
        "# create a sample sentence and tokenize it\n",
        "sample_sentence = ['hello, this is kunal from pakistan']\n",
        "text_vectorizer(sample_sentence) # here we can see we have padded with zero's as there are zeros in the last to complete it to 15"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1400,   19,    9,    1,   20,  811,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4s2KEIjcKF",
        "outputId": "fa36c7e5-75b2-4cdc-edd2-784441b02b94"
      },
      "source": [
        "# choose a random sentence from our training data and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"original sentence:\\n {random_sentence} \\\n",
        "     \\n\\n vectorized_version:\\n\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original sentence:\n",
            " @AdamRubinESPN Familia: arm injury or head case?      \n",
            "\n",
            " vectorized_version:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1, 5670, 4135,  345,   53,  331,  823,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-tbrS1IFZtB",
        "outputId": "fc132e40-f11b-4131-d40f-f84958771727"
      },
      "source": [
        "# getting the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() \n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "print(f\"number of words in vocabulary: {len(words_in_vocab)}\")\n",
        "print(f\"5 most commom words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words in vocabulary: 10000\n",
            "5 most commom words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8DsCEh1J37S"
      },
      "source": [
        "# words_in_vocab -> we can see the vocabulary this way"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9TEKBDFYzNw"
      },
      "source": [
        "## CREATING AN EMBEDDING USING AN EMBEDDING LAYER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4RpmoEaKEC3"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length, output_dim = 128, input_length = max_length)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrVVqAz6Z4XS",
        "outputId": "854a213c-2f32-4c2e-fda2-a5612d6cec37"
      },
      "source": [
        "# get a random sentence from our training data\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"original texrt:\\n {random_sentence} \\\n",
        "       \\n\\n embedded version:\\n \"\n",
        "      )\n",
        "# embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original texrt:\n",
            " Everyday is a near death fatality for me on the road. Thank god is on my side.??        \n",
            "\n",
            " embedded version:\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.01707091,  0.04358722,  0.0428167 , ...,  0.02715712,\n",
              "         -0.04575592, -0.02515835],\n",
              "        [-0.03941928,  0.04088068,  0.02135276, ...,  0.01927103,\n",
              "         -0.00960314, -0.02176775],\n",
              "        [-0.03422534, -0.041835  ,  0.00485262, ..., -0.01490664,\n",
              "         -0.0002969 ,  0.02357397],\n",
              "        ...,\n",
              "        [-0.0074195 , -0.02356559,  0.02812687, ..., -0.04940504,\n",
              "          0.00389164,  0.0249801 ],\n",
              "        [-0.03941928,  0.04088068,  0.02135276, ...,  0.01927103,\n",
              "         -0.00960314, -0.02176775],\n",
              "        [ 0.01900594,  0.04087274, -0.01963401, ...,  0.02724764,\n",
              "         -0.04979111,  0.0220452 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MoRKNuHLhyS",
        "outputId": "305c22fb-bfb7-4321-fece-502e87a9bf12"
      },
      "source": [
        "# check out a single token's embed\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.01707091,  0.04358722,  0.0428167 ,  0.021996  , -0.03269835,\n",
              "         0.04970194, -0.01927955,  0.00736257, -0.04363609,  0.03044752,\n",
              "        -0.00042617,  0.04445574,  0.02001068,  0.04506389,  0.0224406 ,\n",
              "        -0.03186969,  0.00048139,  0.03565839, -0.03712634,  0.04580826,\n",
              "         0.02491525,  0.03313926, -0.00353302,  0.01195226,  0.02682524,\n",
              "        -0.02561603,  0.01428633,  0.0090827 , -0.03629099,  0.01612426,\n",
              "        -0.03489687,  0.01634342, -0.02125598,  0.02090137, -0.01651298,\n",
              "         0.04784283,  0.00812709,  0.01206832, -0.04285739,  0.03064617,\n",
              "         0.04053476,  0.02904927, -0.00046812,  0.03738992,  0.02926734,\n",
              "         0.04007895, -0.00795163,  0.03137249, -0.03573998,  0.01010791,\n",
              "         0.02881316, -0.00115835, -0.03611046,  0.02366597,  0.0029636 ,\n",
              "        -0.01006158, -0.00095798,  0.02829922, -0.04897782, -0.0423503 ,\n",
              "        -0.03182552,  0.02545453, -0.04189019, -0.02472404, -0.04343503,\n",
              "         0.03428223, -0.02222973,  0.0384855 , -0.00610142, -0.0484175 ,\n",
              "         0.04249139, -0.03951131,  0.04751973,  0.01821918, -0.03220751,\n",
              "         0.03728826,  0.03148891,  0.03984908, -0.03419815, -0.02445498,\n",
              "         0.00420352,  0.01509729,  0.04223302,  0.03353563, -0.00656611,\n",
              "         0.01443844, -0.01267065,  0.02073518, -0.00763662,  0.04724574,\n",
              "         0.01291526,  0.01187047,  0.0175495 , -0.04921917,  0.00552855,\n",
              "         0.01777718,  0.04244157, -0.01056234, -0.02719693, -0.0105083 ,\n",
              "        -0.00663658,  0.01761803,  0.02606502,  0.02434279, -0.02599829,\n",
              "        -0.03854662, -0.01697056, -0.03463223, -0.02435331,  0.0493315 ,\n",
              "        -0.00933474, -0.03626334, -0.01231153,  0.04610386, -0.00736501,\n",
              "        -0.02326682, -0.03637534, -0.01770081,  0.0250464 , -0.01673289,\n",
              "        -0.03656492,  0.03458576, -0.03996339, -0.00741947,  0.04793293,\n",
              "         0.02715712, -0.04575592, -0.02515835], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Everyday is a near death fatality for me on the road. Thank god is on my side.??')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fJx0UPiN9pp"
      },
      "source": [
        "### MODEL 0: NAIVE BAYES (BASELINE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgh2pqhrRXY5"
      },
      "source": [
        "* we will use `tfidf` to convert our texts into numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FQ7bKIVOLME",
        "outputId": "085264d4-416c-40f8-a30a-23a61553ca85"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline(\n",
        "    [\n",
        "     ('tfidf', TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "     ('clf', MultinomialNB()) # model the text\n",
        "    ]\n",
        ")\n",
        "\n",
        "# fit the pipeline to our training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw7JKOHsSN-h"
      },
      "source": [
        "# evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "# default evaluatio matrix in scikit learn is accuracy"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1wtOGTpSg45",
        "outputId": "cc12a62d-d891-45b7-f14f-234300e57f8f"
      },
      "source": [
        "print(f\"our baseline model achieves an accuracy of: {baseline_score*100:.2f} %\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our baseline model achieves an accuracy of: 79.27 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1E5jiEkSw8a",
        "outputId": "d1a9f622-6fe9-4764-f740-06e87989c8cb"
      },
      "source": [
        "# we will predict on our validation data now\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x756OVK2U9RO"
      },
      "source": [
        "creating an evaluation function for our model experiments. we will use the following metrics for evaluation.\n",
        "\n",
        "\n",
        "1.   Accuracy\n",
        "2.   Precision\n",
        "3.   Recall\n",
        "4.   F1-score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzmQb1_hU8u8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  calculates model accuracy, precision, recall, f1-score\n",
        "  \"\"\"\n",
        "  # calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # calculate model precision, recall, f1-score using weighted score\n",
        "  precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  model_results = {\n",
        "      'accuracy': model_accuracy,\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1-score': f1_score\n",
        "  }\n",
        "  return model_results"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEwO-ouWZi3S",
        "outputId": "769d7895-c152-4ad9-c2b7-8dbbe6b38ca3"
      },
      "source": [
        "# get baseline results\n",
        "baseline_results = calculate_score(y_true=val_labels,\n",
        "                                     y_pred = baseline_preds,\n",
        "                                     )\n",
        "baseline_results"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1-score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBDOEkk4QWh"
      },
      "source": [
        "### MODEL 1: A SIMPLE DENSE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ8EolJC4Ug1"
      },
      "source": [
        "# create a tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# creating a directory to save our tensorboard logs\n",
        "save_dir = 'model_logs'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0NnPs2C5HJI"
      },
      "source": [
        "# build model with functional API\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype=tf.string) # inputs are one dimensionl strings\n",
        "x = text_vectorizer(input) # turn the inputs into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "output = layers.Dense(1, activation='sigmoid')(x) # create the output layer\n",
        "model_1 = tf.keras.Model(input, output, name='model_1_dense')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qASeR_mL__uk",
        "outputId": "9ed19c22-06b3-4858-c40e-fdef582d45f9"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mk00P-Z7nl1"
      },
      "source": [
        "# compile model_1\n",
        "model_1.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = 'adam',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNBJ_cHJ76dm",
        "outputId": "ca256d0e-02fa-4605-bc59-3545addcf500"
      },
      "source": [
        "# fit the model\n",
        "model_1_history = model_1.fit(train_sentences, train_labels, epochs=5, validation_data=(val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name=save_dir, experiment_name='model_1_dense')])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210823-081449\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 9ms/step - loss: 0.6112 - accuracy: 0.6919 - val_loss: 0.5383 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8197 - val_loss: 0.4698 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3473 - accuracy: 0.8612 - val_loss: 0.4616 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2851 - accuracy: 0.8930 - val_loss: 0.4619 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2390 - accuracy: 0.9092 - val_loss: 0.4768 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAYezvK094Z4",
        "outputId": "f9571edc-eafe-4c04-b24d-6464a061d1a5"
      },
      "source": [
        "# check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4767929017543793, 0.7808399200439453]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k5AQcoz-GYI",
        "outputId": "61f3c39d-eff0-4df4-d7b1-5132b4ae8a61"
      },
      "source": [
        "# make some predictions and evaluate those\n",
        "model_1_pred_prob = model_1.predict(val_sentences)\n",
        "model_1_pred_prob.shape\n",
        "model_1_pred_prob"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50006175],\n",
              "       [0.7583352 ],\n",
              "       [0.9973808 ],\n",
              "       [0.1791971 ],\n",
              "       [0.11235416],\n",
              "       [0.95082545],\n",
              "       [0.92065024],\n",
              "       [0.9942669 ],\n",
              "       [0.9722171 ],\n",
              "       [0.37357482],\n",
              "       [0.15300074],\n",
              "       [0.7105005 ],\n",
              "       [0.0784554 ],\n",
              "       [0.20463477],\n",
              "       [0.00553106],\n",
              "       [0.21343939],\n",
              "       [0.03226073],\n",
              "       [0.11389899],\n",
              "       [0.3729315 ],\n",
              "       [0.6797111 ],\n",
              "       [0.92345095],\n",
              "       [0.04671299],\n",
              "       [0.4760357 ],\n",
              "       [0.11516622],\n",
              "       [0.95940363],\n",
              "       [0.9990096 ],\n",
              "       [0.05221637],\n",
              "       [0.11882791],\n",
              "       [0.03719688],\n",
              "       [0.24096575],\n",
              "       [0.653308  ],\n",
              "       [0.34690052],\n",
              "       [0.49752772],\n",
              "       [0.1958033 ],\n",
              "       [0.6107333 ],\n",
              "       [0.08043661],\n",
              "       [0.99496585],\n",
              "       [0.22249831],\n",
              "       [0.04299125],\n",
              "       [0.9986603 ],\n",
              "       [0.26625407],\n",
              "       [0.02643533],\n",
              "       [0.33698466],\n",
              "       [0.10161106],\n",
              "       [0.69670016],\n",
              "       [0.98577744],\n",
              "       [0.4041463 ],\n",
              "       [0.9203321 ],\n",
              "       [0.24490198],\n",
              "       [0.66424197],\n",
              "       [0.06470679],\n",
              "       [0.56298643],\n",
              "       [0.506391  ],\n",
              "       [0.04068823],\n",
              "       [0.13096516],\n",
              "       [0.04662742],\n",
              "       [0.2625774 ],\n",
              "       [0.96035427],\n",
              "       [0.17288092],\n",
              "       [0.00300306],\n",
              "       [0.21152356],\n",
              "       [0.97352487],\n",
              "       [0.94322157],\n",
              "       [0.21873291],\n",
              "       [0.9308709 ],\n",
              "       [0.98330057],\n",
              "       [0.7689656 ],\n",
              "       [0.43474662],\n",
              "       [0.11995963],\n",
              "       [0.18179874],\n",
              "       [0.10422539],\n",
              "       [0.04235108],\n",
              "       [0.944667  ],\n",
              "       [0.19015546],\n",
              "       [0.20656559],\n",
              "       [0.53007793],\n",
              "       [0.46756366],\n",
              "       [0.86989915],\n",
              "       [0.35379463],\n",
              "       [0.5894156 ],\n",
              "       [0.5017001 ],\n",
              "       [0.33171728],\n",
              "       [0.99705863],\n",
              "       [0.14198746],\n",
              "       [0.20981275],\n",
              "       [0.14871423],\n",
              "       [0.02667039],\n",
              "       [0.12444183],\n",
              "       [0.74854124],\n",
              "       [0.8937927 ],\n",
              "       [0.99269   ],\n",
              "       [0.01916484],\n",
              "       [0.5614539 ],\n",
              "       [0.03981899],\n",
              "       [0.98681355],\n",
              "       [0.75799173],\n",
              "       [0.88156486],\n",
              "       [0.9770786 ],\n",
              "       [0.88624066],\n",
              "       [0.9704695 ],\n",
              "       [0.9991652 ],\n",
              "       [0.20379148],\n",
              "       [0.01554675],\n",
              "       [0.92674977],\n",
              "       [0.91637486],\n",
              "       [0.11180095],\n",
              "       [0.8936619 ],\n",
              "       [0.9780431 ],\n",
              "       [0.06559112],\n",
              "       [0.5856593 ],\n",
              "       [0.7764111 ],\n",
              "       [0.04367164],\n",
              "       [0.26792124],\n",
              "       [0.21614215],\n",
              "       [0.12949252],\n",
              "       [0.591786  ],\n",
              "       [0.5593313 ],\n",
              "       [0.8143105 ],\n",
              "       [0.8108811 ],\n",
              "       [0.12709144],\n",
              "       [0.99980575],\n",
              "       [0.14451289],\n",
              "       [0.1730702 ],\n",
              "       [0.8485395 ],\n",
              "       [0.57147956],\n",
              "       [0.32993844],\n",
              "       [0.86734134],\n",
              "       [0.01105546],\n",
              "       [0.07790819],\n",
              "       [0.8418285 ],\n",
              "       [0.1374626 ],\n",
              "       [0.99980575],\n",
              "       [0.99977833],\n",
              "       [0.9990096 ],\n",
              "       [0.98964614],\n",
              "       [0.11369695],\n",
              "       [0.9796132 ],\n",
              "       [0.21652599],\n",
              "       [0.34018096],\n",
              "       [0.11835413],\n",
              "       [0.9962896 ],\n",
              "       [0.4237709 ],\n",
              "       [0.20463477],\n",
              "       [0.95957637],\n",
              "       [0.35388386],\n",
              "       [0.68274343],\n",
              "       [0.04907981],\n",
              "       [0.01076138],\n",
              "       [0.30347717],\n",
              "       [0.9861742 ],\n",
              "       [0.39761174],\n",
              "       [0.07760616],\n",
              "       [0.5639639 ],\n",
              "       [0.24735291],\n",
              "       [0.30337083],\n",
              "       [0.9929263 ],\n",
              "       [0.86837846],\n",
              "       [0.5363379 ],\n",
              "       [0.9916877 ],\n",
              "       [0.03166656],\n",
              "       [0.9789032 ],\n",
              "       [0.06691218],\n",
              "       [0.2964457 ],\n",
              "       [0.99317205],\n",
              "       [0.3175864 ],\n",
              "       [0.10912272],\n",
              "       [0.9983419 ],\n",
              "       [0.36265847],\n",
              "       [0.9827207 ],\n",
              "       [0.2926491 ],\n",
              "       [0.99353564],\n",
              "       [0.8975036 ],\n",
              "       [0.83406   ],\n",
              "       [0.04093329],\n",
              "       [0.99804425],\n",
              "       [0.07867369],\n",
              "       [0.47137806],\n",
              "       [0.49657536],\n",
              "       [0.7886347 ],\n",
              "       [0.99556893],\n",
              "       [0.02061287],\n",
              "       [0.86937916],\n",
              "       [0.8747859 ],\n",
              "       [0.9762899 ],\n",
              "       [0.98089087],\n",
              "       [0.42980167],\n",
              "       [0.1476917 ],\n",
              "       [0.99935514],\n",
              "       [0.01860096],\n",
              "       [0.03642822],\n",
              "       [0.1406578 ],\n",
              "       [0.93453044],\n",
              "       [0.14163521],\n",
              "       [0.34761146],\n",
              "       [0.01685852],\n",
              "       [0.12357248],\n",
              "       [0.04933513],\n",
              "       [0.21037188],\n",
              "       [0.8006875 ],\n",
              "       [0.08040325],\n",
              "       [0.3151035 ],\n",
              "       [0.91205883],\n",
              "       [0.9810191 ],\n",
              "       [0.44627282],\n",
              "       [0.18814738],\n",
              "       [0.99982613],\n",
              "       [0.634459  ],\n",
              "       [0.9163317 ],\n",
              "       [0.6893338 ],\n",
              "       [0.85582376],\n",
              "       [0.32904404],\n",
              "       [0.9873071 ],\n",
              "       [0.02387163],\n",
              "       [0.24441819],\n",
              "       [0.00733365],\n",
              "       [0.0070515 ],\n",
              "       [0.95691794],\n",
              "       [0.8633585 ],\n",
              "       [0.90789396],\n",
              "       [0.19800307],\n",
              "       [0.70877844],\n",
              "       [0.11675254],\n",
              "       [0.03346808],\n",
              "       [0.22297274],\n",
              "       [0.98650384],\n",
              "       [0.2530938 ],\n",
              "       [0.59227085],\n",
              "       [0.9955852 ],\n",
              "       [0.6457907 ],\n",
              "       [0.66515326],\n",
              "       [0.16552338],\n",
              "       [0.2930831 ],\n",
              "       [0.83740056],\n",
              "       [0.28974804],\n",
              "       [0.60317695],\n",
              "       [0.21871398],\n",
              "       [0.6035741 ],\n",
              "       [0.40188664],\n",
              "       [0.24174395],\n",
              "       [0.10077772],\n",
              "       [0.5194726 ],\n",
              "       [0.3004403 ],\n",
              "       [0.9998977 ],\n",
              "       [0.9901726 ],\n",
              "       [0.10979474],\n",
              "       [0.02815852],\n",
              "       [0.91489935],\n",
              "       [0.1592671 ],\n",
              "       [0.12677462],\n",
              "       [0.5907953 ],\n",
              "       [0.06071061],\n",
              "       [0.60562354],\n",
              "       [0.00101628],\n",
              "       [0.42106414],\n",
              "       [0.9399105 ],\n",
              "       [0.27406043],\n",
              "       [0.98032653],\n",
              "       [0.99917173],\n",
              "       [0.31421706],\n",
              "       [0.22222726],\n",
              "       [0.42487097],\n",
              "       [0.04367728],\n",
              "       [0.00515261],\n",
              "       [0.9890926 ],\n",
              "       [0.9727951 ],\n",
              "       [0.8257488 ],\n",
              "       [0.9664334 ],\n",
              "       [0.06189114],\n",
              "       [0.20382953],\n",
              "       [0.01148868],\n",
              "       [0.25532803],\n",
              "       [0.04811438],\n",
              "       [0.9686035 ],\n",
              "       [0.13133116],\n",
              "       [0.01156449],\n",
              "       [0.97751963],\n",
              "       [0.01537496],\n",
              "       [0.1298596 ],\n",
              "       [0.98682785],\n",
              "       [0.05013744],\n",
              "       [0.10116094],\n",
              "       [0.00888331],\n",
              "       [0.98071176],\n",
              "       [0.6396864 ],\n",
              "       [0.8003496 ],\n",
              "       [0.76840407],\n",
              "       [0.62361544],\n",
              "       [0.07668968],\n",
              "       [0.94504756],\n",
              "       [0.0468913 ],\n",
              "       [0.7778921 ],\n",
              "       [0.4332993 ],\n",
              "       [0.4707337 ],\n",
              "       [0.43972126],\n",
              "       [0.23318069],\n",
              "       [0.7503966 ],\n",
              "       [0.2502355 ],\n",
              "       [0.7330466 ],\n",
              "       [0.15207924],\n",
              "       [0.85156935],\n",
              "       [0.05941027],\n",
              "       [0.10171267],\n",
              "       [0.33223352],\n",
              "       [0.98434514],\n",
              "       [0.21498987],\n",
              "       [0.11942439],\n",
              "       [0.3277213 ],\n",
              "       [0.31297094],\n",
              "       [0.15682125],\n",
              "       [0.04014748],\n",
              "       [0.03688506],\n",
              "       [0.98306227],\n",
              "       [0.4784186 ],\n",
              "       [0.30285254],\n",
              "       [0.99982953],\n",
              "       [0.06903477],\n",
              "       [0.70182025],\n",
              "       [0.33685914],\n",
              "       [0.05699926],\n",
              "       [0.2228085 ],\n",
              "       [0.24457005],\n",
              "       [0.1366762 ],\n",
              "       [0.94214135],\n",
              "       [0.32037544],\n",
              "       [0.98972815],\n",
              "       [0.15759455],\n",
              "       [0.03030762],\n",
              "       [0.9956554 ],\n",
              "       [0.03592329],\n",
              "       [0.9964199 ],\n",
              "       [0.15456513],\n",
              "       [0.05629874],\n",
              "       [0.96984386],\n",
              "       [0.05287401],\n",
              "       [0.04797159],\n",
              "       [0.9844403 ],\n",
              "       [0.00726777],\n",
              "       [0.26299232],\n",
              "       [0.80156714],\n",
              "       [0.93238664],\n",
              "       [0.00566934],\n",
              "       [0.22423865],\n",
              "       [0.98561674],\n",
              "       [0.97058904],\n",
              "       [0.7665584 ],\n",
              "       [0.53957874],\n",
              "       [0.60841787],\n",
              "       [0.46489808],\n",
              "       [0.0816628 ],\n",
              "       [0.13270287],\n",
              "       [0.151349  ],\n",
              "       [0.73930687],\n",
              "       [0.04585614],\n",
              "       [0.5446788 ],\n",
              "       [0.42483172],\n",
              "       [0.01712592],\n",
              "       [0.96979284],\n",
              "       [0.9990096 ],\n",
              "       [0.9944788 ],\n",
              "       [0.03316821],\n",
              "       [0.37597552],\n",
              "       [0.19796732],\n",
              "       [0.4630094 ],\n",
              "       [0.8393976 ],\n",
              "       [0.19774194],\n",
              "       [0.02724839],\n",
              "       [0.09344766],\n",
              "       [0.04870075],\n",
              "       [0.6949632 ],\n",
              "       [0.01458514],\n",
              "       [0.27945673],\n",
              "       [0.05509265],\n",
              "       [0.5166038 ],\n",
              "       [0.3699829 ],\n",
              "       [0.40605533],\n",
              "       [0.25703895],\n",
              "       [0.06890963],\n",
              "       [0.39077866],\n",
              "       [0.09889324],\n",
              "       [0.9966092 ],\n",
              "       [0.9419962 ],\n",
              "       [0.549653  ],\n",
              "       [0.7020577 ],\n",
              "       [0.02522945],\n",
              "       [0.6289354 ],\n",
              "       [0.99319285],\n",
              "       [0.7447003 ],\n",
              "       [0.21556291],\n",
              "       [0.98565245],\n",
              "       [0.25054437],\n",
              "       [0.9519006 ],\n",
              "       [0.33512473],\n",
              "       [0.03304226],\n",
              "       [0.62278366],\n",
              "       [0.5180943 ],\n",
              "       [0.9967301 ],\n",
              "       [0.1504176 ],\n",
              "       [0.06028203],\n",
              "       [0.10341045],\n",
              "       [0.19774194],\n",
              "       [0.9988331 ],\n",
              "       [0.03071747],\n",
              "       [0.71887684],\n",
              "       [0.9789265 ],\n",
              "       [0.11663678],\n",
              "       [0.99980575],\n",
              "       [0.04027385],\n",
              "       [0.46090385],\n",
              "       [0.06440126],\n",
              "       [0.8292    ],\n",
              "       [0.9400649 ],\n",
              "       [0.08284365],\n",
              "       [0.00219094],\n",
              "       [0.25826827],\n",
              "       [0.99215454],\n",
              "       [0.85176027],\n",
              "       [0.15840381],\n",
              "       [0.5314731 ],\n",
              "       [0.8225316 ],\n",
              "       [0.03812316],\n",
              "       [0.99369204],\n",
              "       [0.6470887 ],\n",
              "       [0.99863666],\n",
              "       [0.93809384],\n",
              "       [0.1354592 ],\n",
              "       [0.44326568],\n",
              "       [0.14405353],\n",
              "       [0.9243256 ],\n",
              "       [0.76223546],\n",
              "       [0.4513962 ],\n",
              "       [0.04859646],\n",
              "       [0.41842923],\n",
              "       [0.04816349],\n",
              "       [0.08291389],\n",
              "       [0.15913787],\n",
              "       [0.4198251 ],\n",
              "       [0.57342094],\n",
              "       [0.22224012],\n",
              "       [0.9992618 ],\n",
              "       [0.98575795],\n",
              "       [0.33124742],\n",
              "       [0.7583352 ],\n",
              "       [0.29341102],\n",
              "       [0.0490206 ],\n",
              "       [0.44322813],\n",
              "       [0.7765107 ],\n",
              "       [0.10719299],\n",
              "       [0.3013596 ],\n",
              "       [0.02272682],\n",
              "       [0.57796186],\n",
              "       [0.0031814 ],\n",
              "       [0.9685453 ],\n",
              "       [0.9846543 ],\n",
              "       [0.9944319 ],\n",
              "       [0.97940296],\n",
              "       [0.8452732 ],\n",
              "       [0.23169647],\n",
              "       [0.06356457],\n",
              "       [0.6654985 ],\n",
              "       [0.93747514],\n",
              "       [0.9986628 ],\n",
              "       [0.00392521],\n",
              "       [0.19381934],\n",
              "       [0.24987823],\n",
              "       [0.99905473],\n",
              "       [0.9994392 ],\n",
              "       [0.25729364],\n",
              "       [0.1568573 ],\n",
              "       [0.99718934],\n",
              "       [0.0705917 ],\n",
              "       [0.38681626],\n",
              "       [0.98238856],\n",
              "       [0.19206616],\n",
              "       [0.05303022],\n",
              "       [0.9364147 ],\n",
              "       [0.322221  ],\n",
              "       [0.49358544],\n",
              "       [0.9750505 ],\n",
              "       [0.0402374 ],\n",
              "       [0.06702569],\n",
              "       [0.01301018],\n",
              "       [0.02163609],\n",
              "       [0.1311245 ],\n",
              "       [0.97845185],\n",
              "       [0.03254149],\n",
              "       [0.4951028 ],\n",
              "       [0.62149477],\n",
              "       [0.09794337],\n",
              "       [0.29043186],\n",
              "       [0.08042044],\n",
              "       [0.4391086 ],\n",
              "       [0.9980165 ],\n",
              "       [0.6345664 ],\n",
              "       [0.15441696],\n",
              "       [0.15172368],\n",
              "       [0.16761981],\n",
              "       [0.09961036],\n",
              "       [0.76411647],\n",
              "       [0.02536213],\n",
              "       [0.8962778 ],\n",
              "       [0.8355705 ],\n",
              "       [0.6538458 ],\n",
              "       [0.72773147],\n",
              "       [0.8305572 ],\n",
              "       [0.12548304],\n",
              "       [0.3658153 ],\n",
              "       [0.45478058],\n",
              "       [0.9108177 ],\n",
              "       [0.28035587],\n",
              "       [0.32937422],\n",
              "       [0.41945776],\n",
              "       [0.01804182],\n",
              "       [0.16331552],\n",
              "       [0.4402172 ],\n",
              "       [0.84061265],\n",
              "       [0.17773284],\n",
              "       [0.99458957],\n",
              "       [0.938899  ],\n",
              "       [0.75799173],\n",
              "       [0.9883581 ],\n",
              "       [0.19913487],\n",
              "       [0.11720902],\n",
              "       [0.9193879 ],\n",
              "       [0.22222477],\n",
              "       [0.02226278],\n",
              "       [0.06028674],\n",
              "       [0.16975349],\n",
              "       [0.0014561 ],\n",
              "       [0.87876093],\n",
              "       [0.8265693 ],\n",
              "       [0.8517993 ],\n",
              "       [0.9501895 ],\n",
              "       [0.12796515],\n",
              "       [0.18325707],\n",
              "       [0.7494982 ],\n",
              "       [0.01990139],\n",
              "       [0.3895139 ],\n",
              "       [0.17105363],\n",
              "       [0.6509952 ],\n",
              "       [0.64357615],\n",
              "       [0.06249122],\n",
              "       [0.08630372],\n",
              "       [0.57812643],\n",
              "       [0.15859942],\n",
              "       [0.16642559],\n",
              "       [0.21041462],\n",
              "       [0.21685736],\n",
              "       [0.9990307 ],\n",
              "       [0.98332065],\n",
              "       [0.50119483],\n",
              "       [0.85919046],\n",
              "       [0.9925895 ],\n",
              "       [0.0014797 ],\n",
              "       [0.9741862 ],\n",
              "       [0.25020942],\n",
              "       [0.5342577 ],\n",
              "       [0.34541297],\n",
              "       [0.14267774],\n",
              "       [0.21790163],\n",
              "       [0.03458225],\n",
              "       [0.12380344],\n",
              "       [0.09114787],\n",
              "       [0.7874006 ],\n",
              "       [0.3009336 ],\n",
              "       [0.99387425],\n",
              "       [0.06828829],\n",
              "       [0.7639312 ],\n",
              "       [0.7093943 ],\n",
              "       [0.02170172],\n",
              "       [0.06616104],\n",
              "       [0.9745681 ],\n",
              "       [0.75280285],\n",
              "       [0.9613923 ],\n",
              "       [0.2739323 ],\n",
              "       [0.08785074],\n",
              "       [0.5028822 ],\n",
              "       [0.45366997],\n",
              "       [0.41671968],\n",
              "       [0.9925895 ],\n",
              "       [0.01615568],\n",
              "       [0.04127094],\n",
              "       [0.2016502 ],\n",
              "       [0.9974051 ],\n",
              "       [0.2494146 ],\n",
              "       [0.069768  ],\n",
              "       [0.86803985],\n",
              "       [0.07385195],\n",
              "       [0.02798535],\n",
              "       [0.2319912 ],\n",
              "       [0.31075206],\n",
              "       [0.1844846 ],\n",
              "       [0.3927657 ],\n",
              "       [0.5160408 ],\n",
              "       [0.22687216],\n",
              "       [0.12216137],\n",
              "       [0.43859857],\n",
              "       [0.02430696],\n",
              "       [0.9399191 ],\n",
              "       [0.8378621 ],\n",
              "       [0.5045172 ],\n",
              "       [0.04520172],\n",
              "       [0.02525279],\n",
              "       [0.9908579 ],\n",
              "       [0.5668235 ],\n",
              "       [0.9995937 ],\n",
              "       [0.33486545],\n",
              "       [0.9145018 ],\n",
              "       [0.16694874],\n",
              "       [0.64779246],\n",
              "       [0.7621665 ],\n",
              "       [0.02986207],\n",
              "       [0.9867105 ],\n",
              "       [0.1406664 ],\n",
              "       [0.6031608 ],\n",
              "       [0.9982888 ],\n",
              "       [0.17220248],\n",
              "       [0.03123684],\n",
              "       [0.43162853],\n",
              "       [0.01557364],\n",
              "       [0.56902605],\n",
              "       [0.99982613],\n",
              "       [0.2696878 ],\n",
              "       [0.9595539 ],\n",
              "       [0.31995586],\n",
              "       [0.8171229 ],\n",
              "       [0.2682062 ],\n",
              "       [0.37988687],\n",
              "       [0.0239614 ],\n",
              "       [0.6589426 ],\n",
              "       [0.01681865],\n",
              "       [0.24960841],\n",
              "       [0.94719017],\n",
              "       [0.9455907 ],\n",
              "       [0.9967444 ],\n",
              "       [0.8163568 ],\n",
              "       [0.06532781],\n",
              "       [0.38838714],\n",
              "       [0.01332231],\n",
              "       [0.59956974],\n",
              "       [0.36592793],\n",
              "       [0.90446234],\n",
              "       [0.0503781 ],\n",
              "       [0.8059994 ],\n",
              "       [0.8742176 ],\n",
              "       [0.38066322],\n",
              "       [0.22004767],\n",
              "       [0.32937422],\n",
              "       [0.27590743],\n",
              "       [0.5058419 ],\n",
              "       [0.70201594],\n",
              "       [0.9985474 ],\n",
              "       [0.07798165],\n",
              "       [0.01061864],\n",
              "       [0.02174316],\n",
              "       [0.2822383 ],\n",
              "       [0.29147056],\n",
              "       [0.03900557],\n",
              "       [0.8418792 ],\n",
              "       [0.12185656],\n",
              "       [0.18560907],\n",
              "       [0.25099176],\n",
              "       [0.28974852],\n",
              "       [0.94898015],\n",
              "       [0.24060045],\n",
              "       [0.65015775],\n",
              "       [0.38976634],\n",
              "       [0.02056923],\n",
              "       [0.10645013],\n",
              "       [0.9997273 ],\n",
              "       [0.8687414 ],\n",
              "       [0.00566608],\n",
              "       [0.35725653],\n",
              "       [0.20617464],\n",
              "       [0.10973126],\n",
              "       [0.912809  ],\n",
              "       [0.5089257 ],\n",
              "       [0.748214  ],\n",
              "       [0.42715195],\n",
              "       [0.24531835],\n",
              "       [0.6841542 ],\n",
              "       [0.21178305],\n",
              "       [0.07219308],\n",
              "       [0.9392989 ],\n",
              "       [0.23724802],\n",
              "       [0.4334146 ],\n",
              "       [0.9766011 ],\n",
              "       [0.35325238],\n",
              "       [0.4733485 ],\n",
              "       [0.0014561 ],\n",
              "       [0.33289817],\n",
              "       [0.8564074 ],\n",
              "       [0.99980575],\n",
              "       [0.78966653],\n",
              "       [0.05494918],\n",
              "       [0.9910007 ],\n",
              "       [0.5003791 ],\n",
              "       [0.8673642 ],\n",
              "       [0.5003791 ],\n",
              "       [0.99391127],\n",
              "       [0.01254278],\n",
              "       [0.45400247],\n",
              "       [0.11708231],\n",
              "       [0.9816234 ],\n",
              "       [0.31472185],\n",
              "       [0.49752915],\n",
              "       [0.07091771],\n",
              "       [0.37683493],\n",
              "       [0.121745  ],\n",
              "       [0.02448159],\n",
              "       [0.3281299 ],\n",
              "       [0.07381643],\n",
              "       [0.11346814],\n",
              "       [0.8652213 ],\n",
              "       [0.03098761],\n",
              "       [0.16708024],\n",
              "       [0.04373992],\n",
              "       [0.0176011 ],\n",
              "       [0.1183586 ],\n",
              "       [0.72423357],\n",
              "       [0.08347539],\n",
              "       [0.6934232 ],\n",
              "       [0.1718522 ],\n",
              "       [0.27048585],\n",
              "       [0.8446401 ],\n",
              "       [0.19748358],\n",
              "       [0.07103845],\n",
              "       [0.07158706],\n",
              "       [0.00930632],\n",
              "       [0.9899312 ],\n",
              "       [0.0176011 ],\n",
              "       [0.38528624],\n",
              "       [0.9928883 ],\n",
              "       [0.99291974],\n",
              "       [0.9982666 ],\n",
              "       [0.99988854],\n",
              "       [0.99951327],\n",
              "       [0.24422468],\n",
              "       [0.10723653],\n",
              "       [0.33121598],\n",
              "       [0.6842421 ],\n",
              "       [0.99697053],\n",
              "       [0.5337924 ],\n",
              "       [0.30824026],\n",
              "       [0.62199616],\n",
              "       [0.72254676],\n",
              "       [0.03044865],\n",
              "       [0.00737799],\n",
              "       [0.14350757],\n",
              "       [0.45876318],\n",
              "       [0.01067763],\n",
              "       [0.08892217],\n",
              "       [0.42522556],\n",
              "       [0.9923487 ],\n",
              "       [0.03369422],\n",
              "       [0.937114  ],\n",
              "       [0.776662  ],\n",
              "       [0.08427373],\n",
              "       [0.34985757],\n",
              "       [0.1551014 ],\n",
              "       [0.7577216 ],\n",
              "       [0.44305202],\n",
              "       [0.0135422 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tho96ojwDHTr",
        "outputId": "10a8564e-b30d-427d-c0e8-f76fd326da53"
      },
      "source": [
        "# convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_prob))\n",
        "model_1_preds"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKf0rXrAD1r8",
        "outputId": "e5ade3f2-c029-49e0-bf4b-daf9c15bdf74"
      },
      "source": [
        "# calculate our model_1 results\n",
        "model_1_results = calculate_score(val_labels,model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7798778043941109,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AUmVO2Dw9pq"
      },
      "source": [
        "### VISUALIZING LEARNED EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ihOj5wDxDdN",
        "outputId": "e8c10e13-3c38-4969-b70f-a612f8334f7c"
      },
      "source": [
        "# get vocabulary from our text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # we have previously also instantiated it, but for better visualization we are doing it again here.\n",
        "len(words_in_vocab), words_in_vocab[:20] # twenty most frequent words"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,\n",
              " ['',\n",
              "  '[UNK]',\n",
              "  'the',\n",
              "  'a',\n",
              "  'in',\n",
              "  'to',\n",
              "  'of',\n",
              "  'and',\n",
              "  'i',\n",
              "  'is',\n",
              "  'for',\n",
              "  'on',\n",
              "  'you',\n",
              "  'my',\n",
              "  'with',\n",
              "  'it',\n",
              "  'that',\n",
              "  'at',\n",
              "  'by',\n",
              "  'this'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAf6JcqByLVS",
        "outputId": "cf56ac04-6cf3-4948-c606-304eb1ea29aa"
      },
      "source": [
        "max_vocab_length"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH48OgPSyeFF",
        "outputId": "c0b85652-69dd-4185-c033-bfe6de837a93"
      },
      "source": [
        "# get the weight matrix of our embedding layer which has been learned over 5 epochs\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "embed_weights , embed_weights.shape # for every token in our vocab, it is represented by total of 128 vectors"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.04146543,  0.02975256, -0.01084197, ...,  0.00643798,\n",
              "         -0.03474166, -0.045288  ],\n",
              "        [ 0.00426123, -0.00372232, -0.0314869 , ...,  0.01875492,\n",
              "          0.01280072,  0.05261827],\n",
              "        [-0.00728893,  0.02577698, -0.04471824, ...,  0.06685892,\n",
              "          0.00267629, -0.01728927],\n",
              "        ...,\n",
              "        [-0.04093258,  0.00211409,  0.02172944, ..., -0.03858624,\n",
              "          0.01010894,  0.00446932],\n",
              "        [-0.0065586 , -0.00551059, -0.08302972, ..., -0.01486439,\n",
              "          0.01053048, -0.05819404],\n",
              "        [ 0.09946643, -0.07924651, -0.08286242, ...,  0.04362113,\n",
              "          0.02571165, -0.0845051 ]], dtype=float32), (10000, 128))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmcc18ln1HV2"
      },
      "source": [
        "now we will try to visualize embedding layer into a great tensorflow tool called projector.\n",
        "it is a embedding projector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHGhqoXa0-B0"
      },
      "source": [
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljTm6J528edX"
      },
      "source": [
        "### MODEL 2: LSTM (LONG SHORT TERM MEMORY)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXTiio848khE"
      },
      "source": [
        "# creating model with LSTM layer\n",
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(input)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(input, output, name='model_2')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez57GOzpAE50",
        "outputId": "e0a79c5c-5853-403f-a2e3-50734fb0a639"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OFFXLtyDEgR",
        "outputId": "77211db2-9839-408c-8498-910b836e68ca"
      },
      "source": [
        "train_labels.dtype, val_labels.dtype, train_sentences.dtype, val_sentences.dtype"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), dtype('int64'), dtype('O'), dtype('O'))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4t4MWYlAdJf"
      },
      "source": [
        "# compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1gdTsf3ApFP",
        "outputId": "8f41efa0-eb64-4a3f-df39-bb63eeb9b086"
      },
      "source": [
        "# fitting our model_2 on our training data\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_2_LSTM')])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210823-081503\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 22ms/step - loss: 0.2241 - accuracy: 0.9237 - val_loss: 0.5998 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1590 - accuracy: 0.9407 - val_loss: 0.5337 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1286 - accuracy: 0.9511 - val_loss: 0.6299 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1098 - accuracy: 0.9575 - val_loss: 0.8752 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0872 - accuracy: 0.9651 - val_loss: 0.8929 - val_accuracy: 0.7664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkNWFuxgIMor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a029e657-0e61-41d3-ee66-f06214a9d506"
      },
      "source": [
        "# make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10] # looking at first 10 probabilities"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01480275],\n",
              "       [0.5914624 ],\n",
              "       [0.9999825 ],\n",
              "       [0.11367973],\n",
              "       [0.00103472],\n",
              "       [0.9999032 ],\n",
              "       [0.98574334],\n",
              "       [0.9999908 ],\n",
              "       [0.999984  ],\n",
              "       [0.53589517]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnNMZVlz2baf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749e4704-723f-4d5b-9d06-2a14025a6f45"
      },
      "source": [
        "# converting our prediction probabilities into labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCoMEq833OCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383c70c3-196d-4143-a942-a21174d940cb"
      },
      "source": [
        "# calculate model 2 results\n",
        "model_2_results = calculate_score(val_labels,model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'f1-score': 0.7648999840928975,\n",
              " 'precision': 0.7668867353119322,\n",
              " 'recall': 0.7664041994750657}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8kg0pPI3rsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f96256-dd69-49a8-de77-d2ac19156e4e"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7798778043941109,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N5pfiRd4jHM"
      },
      "source": [
        "### MODEL 3: GRU (GATED RECURRENT UNIT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifCNYyQt4tdF"
      },
      "source": [
        "# another popular and effective component of RNN is GRU\n",
        "# GRU cell has similiar features compared to LSTM cell but has less parameters\n",
        "\n",
        "# building an RNN using GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64, return_sequences=True)(x)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x)\n",
        "# x = layers.GRU(64)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt35R-zL8GYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa516fce-a3c6-4464-be66-98e1cb34d93f"
      },
      "source": [
        "# get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErR3GP548NsC"
      },
      "source": [
        "# compile the model\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZNyJuBk9WfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903fffb2-c1e5-4d4a-ebfc-d4951d867415"
      },
      "source": [
        "# fitting our model_3 on our training data\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_3')])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3/20210823-081528\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 15ms/step - loss: 0.1619 - accuracy: 0.9483 - val_loss: 0.7055 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0918 - accuracy: 0.9658 - val_loss: 0.9723 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0704 - accuracy: 0.9712 - val_loss: 1.3423 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0593 - accuracy: 0.9747 - val_loss: 1.1759 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0512 - accuracy: 0.9768 - val_loss: 1.3639 - val_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me5tpzix9nJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582545c5-e284-4299-d104-bc548d4270b4"
      },
      "source": [
        "model_3_pred_prob = model_3.predict(val_sentences)\n",
        "model_3_pred_prob[:10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.9076050e-02],\n",
              "       [9.6563596e-01],\n",
              "       [9.9999774e-01],\n",
              "       [1.4810225e-01],\n",
              "       [1.8412102e-05],\n",
              "       [9.9998796e-01],\n",
              "       [9.9808830e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.5142555e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdui-uJs9vp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49798aac-a60e-4c64-a2f2-e2d1d35e636a"
      },
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_prob))\n",
        "model_3_preds"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xgi2LZ999Gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec306914-a7a2-48c5-8c4a-395e7ee8d620"
      },
      "source": [
        "model_3_results = calculate_score(val_labels,model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'f1-score': 0.7549846322026649,\n",
              " 'precision': 0.7555819221227483,\n",
              " 'recall': 0.7559055118110236}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou7A8vBL_hPi"
      },
      "source": [
        "### MODEL 4: BIDIRECTIONAL `RNN`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzYEYI7L_put"
      },
      "source": [
        "# building an Bidirectional RNN in tensorflow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB367emxAvX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a807f9-7cdc-4726-fe51-cf7d7d664af9"
      },
      "source": [
        "# getting a summary of the model\n",
        "model_4.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZdUoUKBZsi"
      },
      "source": [
        "# compile the model\n",
        "model_4.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHuoYIr3BcgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eda820f-ed61-4cbe-a454-7728c8689419"
      },
      "source": [
        "# fitting our model_4 on our training data\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_4')])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4/20210823-081553\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 34ms/step - loss: 0.1000 - accuracy: 0.9672 - val_loss: 1.0061 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0555 - accuracy: 0.9749 - val_loss: 1.2989 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.0469 - accuracy: 0.9768 - val_loss: 1.3540 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0406 - accuracy: 0.9774 - val_loss: 1.4618 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0439 - accuracy: 0.9783 - val_loss: 1.4751 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehY-s_UGBkQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1002f5d1-b6b6-4984-826b-eeb165ea82fa"
      },
      "source": [
        "model_4_pred_prob = model_4.predict(val_sentences)\n",
        "model_4_pred_prob[:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3882452e-03],\n",
              "       [8.0651420e-01],\n",
              "       [9.9992800e-01],\n",
              "       [3.6884776e-01],\n",
              "       [2.4832947e-05],\n",
              "       [9.9959022e-01],\n",
              "       [9.9071574e-01],\n",
              "       [9.9995995e-01],\n",
              "       [9.9994206e-01],\n",
              "       [9.9909818e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ip3NyYTBvD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c0af95-c269-4100-ee60-798ae6fab3d0"
      },
      "source": [
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_prob))\n",
        "model_4_preds"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YOkDfFsB1Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d914cf-7333-4c3f-9b52-874247be7acf"
      },
      "source": [
        "model_4_results = calculate_score(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'f1-score': 0.7592519153247733,\n",
              " 'precision': 0.759424508748149,\n",
              " 'recall': 0.7598425196850394}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7bZI_BwDQl0"
      },
      "source": [
        "### MODEL 5: CONV1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6WBQssTDQH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708c1164-7996-452e-b4b6-6cc73b366f6c"
      },
      "source": [
        "# testing our embedding layer, maxpoollayer and convolutional layer\n",
        "\n",
        "embedding_test = embedding(text_vectorizer(['this is a test sentence']))\n",
        "\n",
        "conv_layer = layers.Conv1D(filters=32,\n",
        "                           kernel_size=5, # this is also referred to as ngram of 5, meaning it looks at 5 words at a time.\n",
        "                           strides=1,\n",
        "                           activation='relu',\n",
        "                           padding='same')\n",
        "\n",
        "conv_output = conv_layer(embedding_test) # pass test embedding through convolutional layer\n",
        "\n",
        "pooling_layer = layers.GlobalMaxPool1D() \n",
        "\n",
        "pooling_output = pooling_layer(conv_output) # pass convolutional layer through pooling layer\n",
        "\n",
        "embedding_test.shape, conv_output.shape, pooling_output.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Rb_SgYe-2j",
        "outputId": "97e0c621-35bb-4a8b-f17e-aac329a8a919"
      },
      "source": [
        "# apply 1 dimensional convolutional layer to model sequence\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='valid')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compiling model_5\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# getting the model summary\n",
        "model_5.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh5wSEXqk-gb",
        "outputId": "88cecbdd-a349-461a-8a1d-d0093a37187d"
      },
      "source": [
        "# fitting our model_5 on our training data\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_5')])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5/20210823-081705\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 0.1224 - accuracy: 0.9580 - val_loss: 0.9154 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0749 - accuracy: 0.9729 - val_loss: 1.0678 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0619 - accuracy: 0.9765 - val_loss: 1.1209 - val_accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0576 - accuracy: 0.9766 - val_loss: 1.1658 - val_accuracy: 0.7546\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0515 - accuracy: 0.9799 - val_loss: 1.2174 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01A3N112lFdb",
        "outputId": "daabdb01-0394-4eca-fead-5298185389dc"
      },
      "source": [
        "model_5_pred_prob = model_5.predict(val_sentences)\n",
        "model_5_pred_prob[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.8767914e-01],\n",
              "       [8.1801373e-01],\n",
              "       [9.9997306e-01],\n",
              "       [7.1071811e-02],\n",
              "       [1.5558492e-06],\n",
              "       [9.9851674e-01],\n",
              "       [9.7928613e-01],\n",
              "       [9.9992228e-01],\n",
              "       [9.9999988e-01],\n",
              "       [8.7005198e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeLdL7qhlNqN",
        "outputId": "82a352d1-7500-4241-884c-55c17ab0e33c"
      },
      "source": [
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_prob))\n",
        "model_5_preds"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHVTR0lIlXoR",
        "outputId": "09fee9af-caf4-442b-c82d-3d023d3c84d6"
      },
      "source": [
        "model_5_results = calculate_score(val_labels, model_5_preds) # it did not perform better than our baseline model.\n",
        "model_5_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.80314960629921,\n",
              " 'f1-score': 0.747772153828496,\n",
              " 'precision': 0.7476785153737577,\n",
              " 'recall': 0.7480314960629921}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFIXqFclldqf",
        "outputId": "2116c2bc-b598-4b3a-8646-c55b0f13f6de"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7798778043941109,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex-bsAkenXY8"
      },
      "source": [
        "### MODEL 6: TENSORFLOW HUB PRETRAINED SENTENCE ENCODER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Apvz9Ollh-"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmOoAMB1sHg3"
      },
      "source": [
        "embed_sample = embed([\"sentence will be encoded\",\"universal sentence enocder turns the text into numbers\"])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LFWFjrgsn-v",
        "outputId": "78929566-7268-4284-c96e-f5cee6049242"
      },
      "source": [
        "embed_sample"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[ 0.02344938,  0.00461691,  0.01465249, ..., -0.01021899,\n",
              "         0.04326298, -0.01063718],\n",
              "       [ 0.00858217, -0.07967576, -0.02826347, ..., -0.0003553 ,\n",
              "         0.04516176,  0.00421465]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz8uOsb09LeG"
      },
      "source": [
        "# create a keras layer using universal sentence encoder from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # we passed in empty vector because input text can be of variable length\n",
        "                                        dtype = tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name='USE')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KonMYfyQ-34t",
        "outputId": "a71af15e-ade4-48d0-9b2e-4299912a7cfe"
      },
      "source": [
        "# create model using sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation='relu'),\n",
        "                               layers.Dense(1, activation='sigmoid')\n",
        "], name='model_6')\n",
        "\n",
        "# compiling model_6\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# getting summary\n",
        "model_6.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qcl74-O_ws6",
        "outputId": "f1b97c48-2b32-4309-f4ba-8b1e152f2cdf"
      },
      "source": [
        "# fitting our model_6 on our training data\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_6')])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6/20210823-081738\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 32ms/step - loss: 0.5068 - accuracy: 0.7865 - val_loss: 0.4477 - val_accuracy: 0.8018\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.4144 - accuracy: 0.8146 - val_loss: 0.4451 - val_accuracy: 0.8031\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.4018 - accuracy: 0.8209 - val_loss: 0.4314 - val_accuracy: 0.8136\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3926 - accuracy: 0.8251 - val_loss: 0.4342 - val_accuracy: 0.8084\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3869 - accuracy: 0.8294 - val_loss: 0.4272 - val_accuracy: 0.8110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ_KFJ-sABwW",
        "outputId": "50788b7b-9735-4ad6-c712-7bbeee155a72"
      },
      "source": [
        "model_6_pred_prob = model_6.predict(val_sentences)\n",
        "model_6_pred_prob[:10]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19783682],\n",
              "       [0.85883874],\n",
              "       [0.9914049 ],\n",
              "       [0.23060223],\n",
              "       [0.7941819 ],\n",
              "       [0.772797  ],\n",
              "       [0.9883334 ],\n",
              "       [0.9835707 ],\n",
              "       [0.9519909 ],\n",
              "       [0.11789756]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAoN6xTEAJyu",
        "outputId": "9dbf34db-d7ff-43bd-9d48-e6f80b4c4bf8"
      },
      "source": [
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_prob))\n",
        "model_6_preds"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBg3qvZpAOfo",
        "outputId": "824350fd-4695-4dec-d560-a40deb2a5287"
      },
      "source": [
        "model_6_results = calculate_score(val_labels,model_6_preds) # finally, we have beaten our baseline model.\n",
        "model_6_results"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXP81QGAVID",
        "outputId": "a3b95a26-b0bd-4ef3-e484-76d58e0b4941"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7798778043941109,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VA2G6zcBdr4"
      },
      "source": [
        "### MODEL 7: TENSORFLOW HUB PRETRAINED UNIVERSAL SENTENCE ENCODER WITH 10% OF TRAINING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lnUjhDcBy7i"
      },
      "source": [
        "Transfer learning really helps when we donot have a very large dataset.\n",
        "\n",
        "we will replicate model_6 here but with 10 percent of training data and will see how our model_7 performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or4xFU_ZBdT6"
      },
      "source": [
        "# # NOTE: creating data split like below leaded to data leakage.\n",
        "# # donot split data in such a way that some of the data of test/validation set is present in training set.\n",
        "\n",
        "\n",
        "# # create subsets of 10% of training data\n",
        "# train_10_percent = train_df_shuffled[['text','target']].sample(frac=0.1, random_state=42)\n",
        "# train_10_percent.info()\n",
        "# train_10_percent.head()\n",
        "# train_sentences_10_percent = train_10_percent['text'].to_list()\n",
        "# train_labels_10_percent = train_10_percent['target'].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dftgYETBMWFi",
        "outputId": "d149e13e-8c71-46b0-a5d6-65eceac6d890"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_10_percent_split"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRqRHWyNM4jj",
        "outputId": "c8788446-f7cd-4aa4-b66d-bda76adb1fa2"
      },
      "source": [
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "len(train_sentences_10_percent)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6umMSVNPpQ",
        "outputId": "66bfd678-19e7-4d5e-8740-45939e545bf9"
      },
      "source": [
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_labels_10_percent)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkAaAiPWOK6o",
        "outputId": "4a50dca0-25f7-453c-855a-c72ee0c1acc4"
      },
      "source": [
        "# check the numbe of each label in the updated training dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()\n",
        "\n",
        "# so we have fairly goof distribution, we could have made it more better, but for now, let's take this. "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suz4DYbMD-Kv"
      },
      "source": [
        "# # check the number of targets in our subset of data\n",
        "# train_10_percent['target'].value_counts()\n",
        "\n",
        "# # so we have roughly same distribution of labels. it is neccessary as if distribution is not equal, \n",
        "# #the predictions will be vague sometimes due to the model not being trained enoough with particular text corresponding to the target."
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nOPFh3hEd_F"
      },
      "source": [
        "# train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA13iG6TF3b_",
        "outputId": "b208e2b9-4bcb-45e9-eec9-c61d5a2b0046"
      },
      "source": [
        "# let's build a model same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# compile model_7\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# getting the summary\n",
        "model_7.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E43etJ6GTgw",
        "outputId": "8169adc4-80a2-4474-b2e5-2d79f5cad19e"
      },
      "source": [
        "# fitting our model on our 10 percent of training data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent, train_labels_10_percent, epochs=5,\n",
        "                              validation_data = (val_sentences, val_labels), \n",
        "                              callbacks=[create_tensorboard_callback(dir_name=save_dir, experiment_name='model_7_with correct split')])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_with correct split/20210823-081809\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 6s 152ms/step - loss: 0.6664 - accuracy: 0.6745 - val_loss: 0.6466 - val_accuracy: 0.7100\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5970 - accuracy: 0.7912 - val_loss: 0.5907 - val_accuracy: 0.7480\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 45ms/step - loss: 0.5221 - accuracy: 0.8175 - val_loss: 0.5372 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4616 - accuracy: 0.8219 - val_loss: 0.5045 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4206 - accuracy: 0.8321 - val_loss: 0.4919 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXfBpkNcH6-C",
        "outputId": "145e8bdc-535e-46f5-cbc3-c466b04c93d1"
      },
      "source": [
        "model_7_pred_prob = model_7.predict(val_sentences)\n",
        "model_7_pred_prob[:10]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19934306],\n",
              "       [0.57541347],\n",
              "       [0.9073732 ],\n",
              "       [0.35801095],\n",
              "       [0.5494603 ],\n",
              "       [0.67518103],\n",
              "       [0.88096356],\n",
              "       [0.8096875 ],\n",
              "       [0.84383434],\n",
              "       [0.14835522]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAz185TKIBnf",
        "outputId": "5ab005bd-1451-45b2-d622-a59c120ec3cc"
      },
      "source": [
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_prob))\n",
        "model_7_preds"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtAq60TbIFXZ"
      },
      "source": [
        "# calculate_score(val_labels, model_7_preds)\n",
        "\n",
        "# # the results we have got with 10 percent of our training data is even better than\n",
        "# # the results we got after training our model on whole datasets. why is it so?\n",
        "\n",
        "# # this is the problem of data leakage.\n",
        "# # we created 10 percent dataset using train_df_shuffled and also we created val_sentences using train_df_shuffled.\n",
        "# # some of the data is already present in train_10_percent which are present in train_df_shuffled. so our has some seen data \n",
        "# # and thus it performs better because it has learned."
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNaVT74QQn64",
        "outputId": "5c5a816e-a533-4aa8-af16-560165173efb"
      },
      "source": [
        "model_7_results = calculate_score(val_labels, model_7_preds)\n",
        "model_7_results\n",
        "# now we can see the accuracy of the model trained with 10 percent of data is less.\n",
        "# we could not outperform our baseline model"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7790338643605079,\n",
              " 'precision': 0.7823342077218286,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWD3H2C3IQ__",
        "outputId": "53860987-2e95-4586-c40a-09f3f99fcacc"
      },
      "source": [
        "calculate_score(val_labels, model_6_preds)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY54_BBmQ_sZ",
        "outputId": "afffa94e-a1c8-445d-d78f-9bbea1621623"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1-score': 0.7798778043941109,\n",
              " 'precision': 0.7809067257781027,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USla2zVuRdlZ"
      },
      "source": [
        "### COMPARING THE PERFORMANCE OF EACH OF OUR MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyg9z2BgRQow"
      },
      "source": [
        "# combine model results into a dataframe\n",
        "all_models_result = pd.DataFrame({'baseline': baseline_results,\n",
        "                                  'simple_dense': model_1_results,\n",
        "                                  'LSTM': model_2_results,\n",
        "                                  'GRU': model_3_results,\n",
        "                                  'bidirectional': model_4_results,\n",
        "                                  'Conv1D': model_5_results,\n",
        "                                  'transfer_learning': model_6_results,\n",
        "                                  'transfer_learning_on_10%_data': model_7_results})\n",
        "all_models_result = all_models_result.transpose()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXJcf3k_VSPw"
      },
      "source": [
        "# reduce the accuracy to the same scale as other metrics\n",
        "all_models_result['accuracy'] = all_models_result['accuracy']/100.0"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "qhsq3Dr5V1hH",
        "outputId": "3d5df99d-0405-4ba9-a440-100c29182a2e"
      },
      "source": [
        "all_models_result"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780907</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.779878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766887</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.755582</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.754985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759425</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conv1D</th>\n",
              "      <td>0.748031</td>\n",
              "      <td>0.747679</td>\n",
              "      <td>0.748031</td>\n",
              "      <td>0.747772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>transfer_learning</th>\n",
              "      <td>0.811024</td>\n",
              "      <td>0.811117</td>\n",
              "      <td>0.811024</td>\n",
              "      <td>0.810385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>transfer_learning_on_10%_data</th>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.782334</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.779034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               accuracy  precision    recall  f1-score\n",
              "baseline                       0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense                   0.780840   0.780907  0.780840  0.779878\n",
              "LSTM                           0.766404   0.766887  0.766404  0.764900\n",
              "GRU                            0.755906   0.755582  0.755906  0.754985\n",
              "bidirectional                  0.759843   0.759425  0.759843  0.759252\n",
              "Conv1D                         0.748031   0.747679  0.748031  0.747772\n",
              "transfer_learning              0.811024   0.811117  0.811024  0.810385\n",
              "transfer_learning_on_10%_data  0.780840   0.782334  0.780840  0.779034"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "bINsly72V_sE",
        "outputId": "da526182-b2a8-4856-a7fd-fe756c115b1a"
      },
      "source": [
        "# plot and compare all of the model results\n",
        "all_models_result.plot(kind='bar', figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "oe3eqmPUZvau",
        "outputId": "124bd96b-edd9-4aa2-c1ff-cf1205301adf"
      },
      "source": [
        "# sort model results by f1-score\n",
        "all_models_result.sort_values('f1-score', ascending=False)['f1-score'].plot(kind='bar', figsize=(10,7));"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAIvCAYAAABQoV5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xndV3v8dfbAbxxkWKOGXcNNVIUG9DUvKWFN6g0A/Ucb0hZGEV1xJMHPXQxtbxkVFJ5LUW0jk2KkXnPJGa4CA6IzkGRwSxEFNKUi5/zx1obfrPZM7Nnrz37u4b1ej4e+8Fe67eY/fbnsPd7r+93fb+pKiRJkrQ0d2odQJIkaWdmmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBdmn1hffZZ5866KCDWn15SZKkRTv//PO/VlWrF3qtWZk66KCDWL9+fasvL0mStGhJrtzSaw7zSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIG2KV1gKEOOuUDrSMA8KXff3LrCJIkqYFF3ZlKclSSy5NsTHLKAq8fkOSjSS5McnGSJy1/VEmSpPHZZplKsgo4HXgicChwXJJD5132MuCsqjocOBb4k+UOKkmSNEaLuTN1JLCxqq6oqhuBM4Fj5l1TwJ7953sBX1m+iJIkSeO1mDK1L3DVzPGm/tysVwDPTrIJOBt48UJ/UJITkqxPsv6aa65ZQlxJkqRxWa6n+Y4D3lpV+wFPAt6R5HZ/dlWdUVVrqmrN6tWrl+lLS5IktbOYMnU1sP/M8X79uVkvAM4CqKpPA3cB9lmOgJIkSWO2mDK1DjgkycFJdqObYL523jVfBn4CIMkP05Upx/EkSdId3jbLVFXdDJwInANcRvfU3oYkpyU5ur/s14EXJvkM8C7guVVVOyq0JEnSWCxq0c6qOptuYvnsuVNnPr8UeMTyRpMkSRo/t5ORJEkaYKffTka3N5YtdsBtdiRJd3zemZIkSRrAO1OaDO/YSZJ2BMuUNHGWTEkaxmE+SZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsCn+SRpAWN5ytEnHKXx886UJEnSAJYpSZKkARzmkyQtyliGPsHhT42Ld6YkSZIG8M6UJEkDeMdO3pmSJEkawDIlSZI0gMN8kiRp2U1p+NM7U5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJAyyqTCU5KsnlSTYmOWWB11+X5KL+4/NJvrH8USVJksZnl21dkGQVcDrwBGATsC7J2qq6dO6aqvq1metfDBy+A7JKkiSNzmLuTB0JbKyqK6rqRuBM4JitXH8c8K7lCCdJkjR2iylT+wJXzRxv6s/dTpIDgYOBj2zh9ROSrE+y/pprrtnerJIkSaOz3BPQjwXeW1W3LPRiVZ1RVWuqas3q1auX+UtLkiStvMWUqauB/WeO9+vPLeRYHOKTJEkTspgytQ44JMnBSXajK0xr51+U5P7A3sCnlzeiJEnSeG2zTFXVzcCJwDnAZcBZVbUhyWlJjp659FjgzKqqHRNVkiRpfLa5NAJAVZ0NnD3v3Knzjl+xfLEkSZJ2Dq6ALkmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAiypTSY5KcnmSjUlO2cI1z0hyaZINSd65vDElSZLGaZdtXZBkFXA68ARgE7AuydqqunTmmkOAlwKPqKrrkvy3HRVYkiRpTBZzZ+pIYGNVXVFVNwJnAsfMu+aFwOlVdR1AVf3H8saUJEkap8WUqX2Bq2aON/XnZt0XuG+STyU5N8lRyxVQkiRpzLY5zLcdf84hwGOA/YBPJHlgVX1j9qIkJwAnABxwwAHL9KUlSZLaWcydqauB/WeO9+vPzdoErK2qm6rqi8Dn6crVZqrqjKpaU1VrVq9evdTMkiRJo7GYMrUOOCTJwUl2A44F1s675n10d6VIsg/dsN8Vy5hTkiRplLZZpqrqZuBE4BzgMuCsqtqQ5LQkR/eXnQNcm+RS4KPAb1bVtTsqtCRJ0lgsas5UVZ0NnD3v3Kkznxdwcv8hSZI0Ga6ALkmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBFlWmkhyV5PIkG5OcssDrz01yTZKL+o/jlz+qJEnS+OyyrQuSrAJOB54AbALWJVlbVZfOu/TdVXXiDsgoSZI0Wou5M3UksLGqrqiqG4EzgWN2bCxJkqSdw2LK1L7AVTPHm/pz8z0tycVJ3ptk/2VJJ0mSNHLLNQH974GDquow4EPA2xa6KMkJSdYnWX/NNdcs05eWJElqZzFl6mpg9k7Tfv25W1XVtVX13f7wL4AfXegPqqozqmpNVa1ZvXr1UvJKkiSNymLK1DrgkCQHJ9kNOBZYO3tBknvNHB4NXLZ8ESVJksZrm0/zVdXNSU4EzgFWAW+uqg1JTgPWV9Va4FeSHA3cDHwdeO4OzCxJkjQa2yxTAFV1NnD2vHOnznz+UuClyxtNkiRp/FwBXZIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDLKpMJTkqyeVJNiY5ZSvXPS1JJVmzfBElSZLGa5tlKskq4HTgicChwHFJDl3guj2Ak4B/Xe6QkiRJY7WYO1NHAhur6oqquhE4Ezhmget+G3gV8J1lzCdJkjRqiylT+wJXzRxv6s/dKslDgP2r6gNb+4OSnJBkfZL111xzzXaHlSRJGpvBE9CT3Al4LfDr27q2qs6oqjVVtWb16tVDv7QkSVJziylTVwP7zxzv15+bswfwAOBjSb4EPAxY6yR0SZI0BYspU+uAQ5IcnGQ34Fhg7dyLVfXNqtqnqg6qqoOAc4Gjq2r9DkksSZI0ItssU1V1M3AicA5wGXBWVW1IclqSo3d0QEmSpDHbZTEXVdXZwNnzzp26hWsfMzyWJEnSzsEV0CVJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0wKLKVJKjklyeZGOSUxZ4/ReTXJLkoiT/nOTQ5Y8qSZI0PtssU0lWAacDTwQOBY5boCy9s6oeWFUPBl4NvHbZk0qSJI3QYu5MHQlsrKorqupG4EzgmNkLqur6mcO7A7V8ESVJksZrl0Vcsy9w1czxJuCh8y9K8svAycBuwOMW+oOSnACcAHDAAQdsb1ZJkqTRWbYJ6FV1elXdB3gJ8LItXHNGVa2pqjWrV69eri8tSZLUzGLK1NXA/jPH+/XntuRM4KeHhJIkSdpZLKZMrQMOSXJwkt2AY4G1sxckOWTm8MnAF5YvoiRJ0nhtc85UVd2c5ETgHGAV8Oaq2pDkNGB9Va0FTkzyeOAm4DrgOTsytCRJ0lgsZgI6VXU2cPa8c6fOfH7SMueSJEnaKbgCuiRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDLKpMJTkqyeVJNiY5ZYHXT05yaZKLk3w4yYHLH1WSJGl8tlmmkqwCTgeeCBwKHJfk0HmXXQisqarDgPcCr17uoJIkSWO0mDtTRwIbq+qKqroROBM4ZvaCqvpoVX27PzwX2G95Y0qSJI3TYsrUvsBVM8eb+nNb8gLgg0NCSZIk7Sx2Wc4/LMmzgTXAo7fw+gnACQAHHHDAcn5pSZKkJhZzZ+pqYP+Z4/36c5tJ8njgt4Cjq+q7C/1BVXVGVa2pqjWrV69eSl5JkqRRWUyZWgcckuTgJLsBxwJrZy9IcjjwJroi9R/LH1OSJGmctlmmqupm4ETgHOAy4Kyq2pDktCRH95e9BtgdeE+Si5Ks3cIfJ0mSdIeyqDlTVXU2cPa8c6fOfP74Zc4lSZK0U3AFdEmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNsKgyleSoJJcn2ZjklAVef1SSC5LcnOTpyx9TkiRpnLZZppKsAk4HnggcChyX5NB5l30ZeC7wzuUOKEmSNGa7LOKaI4GNVXUFQJIzgWOAS+cuqKov9a99bwdklCRJGq3FDPPtC1w1c7ypP7fdkpyQZH2S9ddcc81S/ghJkqRRWdEJ6FV1RlWtqao1q1evXskvLUmStEMspkxdDew/c7xff06SJGnyFlOm1gGHJDk4yW7AscDaHRtLkiRp57DNMlVVNwMnAucAlwFnVdWGJKclORogyRFJNgE/B7wpyYYdGVqSJGksFvM0H1V1NnD2vHOnzny+jm74T5IkaVJcAV2SJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBrBMSZIkDWCZkiRJGsAyJUmSNIBlSpIkaQDLlCRJ0gCWKUmSpAEsU5IkSQNYpiRJkgawTEmSJA1gmZIkSRrAMiVJkjSAZUqSJGkAy5QkSdIAlilJkqQBLFOSJEkDWKYkSZIGsExJkiQNYJmSJEkawDIlSZI0gGVKkiRpAMuUJEnSAJYpSZKkASxTkiRJAyyqTCU5KsnlSTYmOWWB1++c5N396/+a5KDlDipJkjRG2yxTSVYBpwNPBA4Fjkty6LzLXgBcV1U/BLwOeNVyB5UkSRqjxdyZOhLYWFVXVNWNwJnAMfOuOQZ4W//5e4GfSJLliylJkjROqaqtX5A8HTiqqo7vj/878NCqOnHmms/212zqj/9ff83X5v1ZJwAn9If3Ay5frv8hA+0DfG2bV02P78vt+Z4szPdlYb4vC/N9uT3fk4WN6X05sKpWL/TCLiuZoqrOAM5Yya+5GEnWV9Wa1jnGxvfl9nxPFub7sjDfl4X5vtye78nCdpb3ZTHDfFcD+88c79efW/CaJLsAewHXLkdASZKkMVtMmVoHHJLk4CS7AccCa+ddsxZ4Tv/504GP1LbGDyVJku4AtjnMV1U3JzkROAdYBby5qjYkOQ1YX1Vrgb8E3pFkI/B1usK1Mxnd0ONI+L7cnu/JwnxfFub7sjDfl9vzPVnYTvG+bHMCuiRJkrbMFdAlSZIGsExJkiQNYJmSJEkawDIlSZI0wIou2jkmSS4B5s++/yawHvidqprsOllJHgkcUlVvSbIa2L2qvtg6VytJ7gb8OnBAVb0wySHA/arq/Y2jNdX/3XgJ3Z6dd5k7X1WPaxaqoSQnb+31qnrtSmUZkyTft7XXq+rrK5VlLBZ4Twr4hksKQZLvB54J3L8/dRnwrrH/TJ5smQI+CNwCvLM/Pha4G/BV4K3AU9vEaivJy4E1dNv9vAXYFfgr4BEtczX2FuB84Mf646uB9wCTLlPAXwPvBp4M/CLdWnPXNE3U1h8AF9F9b/ku4P6knfPpysJC70cB917ZOKOw0Huye5LPAMdX1ZeapGosyQ8DH6FbiulCuvfnCOB/JXlcVX2uZb6tmezSCEkuqKqHLHQuySVV9cBW2VpKchFwOHBBVR3en7u4qg5rm6ydue0Mklw48558pqoe1DpbS0nOr6ofnf37kWRdVR3ROlsLSR4EHAccRffD8l3Ah73boMVK8rPACVV1VOssLSR5L3BWVZ017/zTgGdW1dPaJNu2Kc+ZWpXkyLmDJEfQLUoKcHObSKNwY//NvwCS3L1xnjG4Mcldue09uQ/dnYepu6n/578leXKSw4GtDunckVXVZ6rqlKp6MN1CxscAlyY5unG00Uiyd5Ijkzxq7qN1pjGpqr8F/lvrHA09cH6RAqiqvwEe0CDPok15mO944M1Jdqe7lXg9cHxfHl7ZNFlbZyV5E3CPJC8Eng/8eeNMrb0c+Adg/yR/TTfk+dymicbhd5LsRTef7I3AnsCvto3UXj+X7HDggcAm4D/aJhqHJMcDJ9Ht73oR8DDg08Ak59gtpP95NOWbHN9a4mvNTXaYb07/w4Cq+mbrLGOR5AnAT9KVzHOq6kONIzXXT4p8GN17cm5Vfa1xpOaSPKKqPrWtc1OR5PnAM+gm488NV1ikev1DP0fQ/ffz4CT3B36vqn62cbQVt4WHFfYGjgb+uKom+Qtskk3AQg9qBPjVqtp/hSMt2mTLVJI7A08DDmLmDl1VndYqk8YpySOAi6rqW0meDTwEeENVXdk4WlNbm3fYKlNLSb4HfBaY+3ux2TfXqpr0cN/cfLp+XuZDq+q7STZU1Y+0zrbS+gd9ZhVwLfCJqrqkQaRRWOB92UxV/Z+VyrK9pjzM93d0SyGcj/NfbtVPgHwV3bh9+o+qqj2bBmvrT4EH9ROMT6abD/N24NFNUzWS5MeAhwOr5/2GvSe3zTucose2DjBym5LcA3gf8KEk13Fb8ZyUrZWCJAdU1ZdXMs9YjLksbcuUy9R+U31iYhteDTy1qi5rHWREbq6qSnIMcHpV/WWSF7QO1dBuwO503z/2mDl/PfD0JonG4XlV9dzWIcaqqn6m//QVST4K7EU3F3GS+l9K9qW7G/UfSQ4DTgF+HBjtcFYrSU4d88jRlIf5zgDeOOVbqgtJ8qmqmvKaUreT5ON03/SfBzyKbkLxZ6a6fMacJAdOfahz1pSHOBcrySrgnmw+tWJyd2GSvAZ4Ct1E/B+iW1fpeLqHn95UVd9pGG+Ukny5qg5onWNLplymLqX7S/xFbltgr6a8nhJAkjcAP0B3K/7W4c/+kd1JSvIDdCvyrquqTyY5AHhMVb29cbSm+qfW/ifwI7gCOkk+R7fO1IKLdVbVBSubaFySvJjuydh/B77Xn57k99z+589Dquo7SfYGrgIeMNXFOuckuX5LLwF3rarRjqZNuUwduND5qf+mneQtC5yuqnr+iofRqCX5R7oV0H+DmRXQq+olTYM1kuQGYB1bWOl7qiVzTpKNdBPPR70tyEqYfxdzdkHgKUvyZeCIqvr3BV67asxP84225e0oSfasquuBG1pnGaOqel7rDGPjpPwt+v5+/thJVfVx4ONJ1rUO1dDGqRembbiK7qEfwb2TrJ05Prg/nvveMtUnP98OHEh393K+dy5wbjQmV6bo/g95CgvvjTTVfaJI8j+r6tVJ3sjtN4Cmqn6lQayxcFL+wjZbAR34ChNeAV3bdAXwsSQfYPMpBFPcAPqYecd/yG3fdye7p2NVvWwrr436jvfkylRVPaX/58Gts4zMXFFY3zTFOP27RWpBC62A/mttIzW12Tf7JLvSbYFxtYt3AvDl/mO3/mPK7kH3RPnpAEnOA1bTFapRl4aVkOTv6fa2/LuqGvXK53MmO2cKIMm+dLcUZ58s+US7RBojJ+VrMZL8Gd0Twhv6kvlp4Ba6u3W/UVXvahpwJPotU6iq/2ydpZUknwKOraqr+uOLgJ8A7g68pap+omW+1pI8Gvh54Ml08xDPBN4/5qccJ3dnak6SV9H9n3Up3Tc86H4rmGSZ6n8T2GKznvAYPnR3XL5Nt8XOnAImWaa2NBQ8Z8JDwj9eVb/Yf/484PNV9dP906AfpPtNe7KSPAB4B/1QcJKvAf+jqjY0DdbGbnNFqvfP/cT8a91cHmbmYK6i27vxhcCb6b4Xj9JkyxTw08D9qsrVzzt/0DrAWDkp/3bmhoIfARxK90QfwM/R/XIyVTfOfP4E4D0AVfXVZLLTYGadAZxcVR8FSPIYuk3UH94yVCN7zx5U1Ykzh6tXOMsoJbkr8FS6mx4PAd7WNtHWTblMXQHsilvJALf+JgDc+pf4gKq6vGGk0UhyX7otZe5ZVQ/oVyo+uqp+p3G0JqrqbQBJXgQ8sqpu7o//DPhky2yNfSPJU4Cr6YrmCwCS7ALctWWwkbj7XJECqKqPTfguzL8meeH8DY2T/AJwXqNMo5HkLOBIusWS/xj4eFV9b+v/VltTLlPfBi5K8mE2nwcz1SEKAJI8le4u1W50j+s+GDht4sN8fw78JvAmgKq6OMk7gUmWqRl70912/3p/vDvzfuOemF8A/ohuft2vVtVX+/M/AXygWarxuCLJ/6Yb6gN4Nt0vtVP0a8D7kjwTmFvM9UeBO9ONmkzdXwLHVdUt27xyJKZcptb2H9rcK+h+I/gYQFVdlGTqTz7erarOmzdUc3OrMCPy+8CF/T5rodtq5xVNEzVUVZ8HbrffZ1Wdk+SHG0Qam+cD/4fb5hp+sj83Of3TnQ9P8ji6HQQAPlBVH2kYazT6/2YenuQgNn9AbLS7TkyyTPWT2p5bVe7yfns3VdU35xWH6T7y2flakvvQvw9Jng78W9tI7VXVW5J8EHhof+olM3djSPIjE51cvJCTgde3DtFSVV0HTPrO/3x9ebJAzZPkHcB96PYunH1AzDI1JlV1S5LvJdmrqlyRd3Mb+lvPq5IcQvfN718aZ2rtl+kmz94/ydV0+zk+u22kcejL099t4eV30E0c1YQXYkzy+qr61S09MTzxKQRa2Brg0NqJ1m6aZJnq/SdwSZIPAbcuCjb1OVPAi4HfoptH9i663cx/u2mixqrqCuDx/WTZO1WVWxEtzmQLxAJ2mh8KO8DcHCmfGNZifZZu7uFOMwIw5TL1t0x0naCtqapv05Wp3+qHQ+8+5oXSdqQkJ2/hPDDZbTC2x6QKRL/R8UL/m8OEn+arqvP7Tx9cVW+YfS3JScDHb/9vaeL2AS7tV4affUBstHcxJ1um5h7v1ub6p9R+kW6ceh2wZ5I3VNVr2iZrYo/+n/cDjuC2Bxaeio8va56q2mPbV03ac4A3zDv33AXOSa9oHWB7TXY7mX4+0CvpFh28y9z5qprkRsdzklxUVQ9O8iy6+S6nAOdX1WGNozWT5BPAk+eG95LsQffkzaPaJhu3JOdW1cNa51BbSY4Dngk8ks3XIdsD+N7Ut07RwpLck+6XWIDzxr6/5WTvTAFvAV4OvA54LN32D3dqmmgcdu03aP1p4I+r6qYk02zct7knm69ufWN/TkCS1cBJdENZf1ZVXwCwSKn3L3RzX/YB/nDm/A3AxU0SadSSPAN4Dd0SPQHemOQ3q+q9TYNtxZTL1F2r6sNJUlVXAq9Icj5wautgjb0J+BLwGeATSQ4Erm+aqL23A+cl+b/98U8Db20XZ3T+kG5h0wLeyW2/TUr031+v7O92f2VuDma/08J+dN9vpFm/BRwxdzeq/4Xtn4DRlqkp34n5bpI7AV9IcmKSn6FbwXnSquqPqmrfqnpSda6ku3M3WVX1u3R3Lq/rP55XVa+cez3JpFb9TnJOktkhzt3ofiB+iW4FZ2khZwGzW4LcQr9/oTTPneYN613LyPvKlOdMHQFcBtyD7tH/PYHXVNW5TYONQJIn063KOzuX7LR2icYtyQVVNZn1lJLsBbyM7q7Cy+i+yb2cbpjvdVX1zw3jaaTm5mPOO/eZqnpQq0wapySvAQ6jW54Hus2OL66ql7RLtXWTHearqnUASb5XVc9rnWcs+s1q70Z3N+ovgKfjk2vbMqn1lPqFbn8zyb2B3wW+ApxYVd9om0wjd02So6tqLUCSY4CvNc6kEUnyQ3Qbyv9mkp+le2gB4NPAX7dLtm1TvjP1Y3SbKe5eVQckeRDwC1X1S42jNQclp+sAAA/DSURBVJXk4qo6bOafuwMfrKofb51trCZ4Z+o+wIvoJuL/Md22Dy+j28z39J1pc1KtnP7vzV8D+9LNr9sE/I+q2tg0mEYjyfuBl1bVJfPOPxD4vap6aptk2zbqMcgd7PXAT9GNxVJVn6HbqHXq/qv/57eT/CBwE3Cvhnk0Pu+iW/D2o8A7quqTVfVTwDeAf2yaTKNVVf+vf8Lzh+m2Cnm4RUrz3HN+kQLozx208nEWb8pliqq6at4pf6OG9ye5B/Bq4Hy6ScXv2uq/oUkN89FNMv8i3d+Nu82d7Hd0f0qjTBq5JPdM8pfAe6rqP5McmuQFrXNpVO6xlddGvYvAlMvUVUkeDlSSXZP8Bt2E9Kn7A+D5wH+nG6d+Nd28mElL8sgkz+s/X53k4JmXp7bo4IvohvdOo1st/1ZV9V8L/htSt5zIOcAP9sefB361WRqN0fokL5x/MsnxdL/cj9aU50ztQ7eNwePp7iz8I3BSVV3bNFhjSc6iW0zvr/pTzwT2qqpntEvVVpKX0+1ifr+qum8//PmeqnpE42jNJfk+gKr6eussGrck66rqiCQXVtXh/bnbPeGn6epXPf+/dPMx58rTGrrlV36mqr7aKtu2TPlpvq8Bz2qdY4QeUFWHzhx/NMmlzdKMw88AhwMXAFTVV/otZSYpyQF0dywfB3yzO5U9gY8Ap1TVlxrG03h9K8n3028GneRhdH9/JACq6t+Bhyd5LPCA/vQHquojDWMtyuTKVJI3spXd7KvqV1YwzhhdkORhc+ttJXkosL5xptZurKqa21Ynyd1bB2rs3XQPcDxr7sm9JKuAnwPOBNxGRgs5mW6z8Psk+RSwmm7pFWkzVfVRugdcdhqTK1NYDBaU5BK6krkr8C9JvtwfHwh8rmW2ETgryZuAe/Tj+c+n2z5lqvapqnfPnuhL1ZlJfrtRJo1YX7Yf3X/cj25qxeVVdVPTYNIymeycqW1J8saqenHrHCul34Nvi/ptZSYryROAn6T7IXBOVX2ocaRmkpwJfB14GzD3ROz+wHPoitZk59dpy5KcV1VHts4h7QiWqS2Y2kKM0mIl2Q14AXAM3QKM0C3A+PfAX1bVd1tl03gleR3dne93A9+aO19VFzQLJS0Ty9QWWKaU5AYWnl8XoKpqzxWOJO20kiw0B6aq6nErHkZaZlOcMyUtSlVN9om9pUpyqptiayFV9djWGaQdxTtTWzC7FoqU5CF0m24W8M9VdWHjSKOU5MtVdUDrHBqPJM+uqr9KcvJCr1fVa1c6k7TcJrkCepJVSf5gG5e9YUXCaPSSnEo32fr7gX2AtyZ5WdtU7SS5fgsfN3Db6tbSnLmlRPbYwoe005vsnakk5/abbkpbleRy4EFV9Z3++K7ARVV1v7bJ2uiXzTiiX2Bv/mtXVdX+DWJJUjNTnjN1YZK1wHvY/MmSv20XSSP1FeAuwHf64zsDV7eL09zb6dYfu12ZAt65wlk0ckn+aGuvu1Cy7gimfGfqLQucrqp6/oqH0agleR9wBPAhujlTTwDOo1sOwB8GW5DkR6pqQ+scaivJc/pPHwEcSrc0AnQr5l9aVb+44L8o7UQmW6akxZr5YbCgqnrbSmXZmbi8iGYlORd4ZFXd3B/vCnzS6Ra6I5jsMF+S+wJ/Ctyzqh6Q5DDg6Kr6ncbRNDKWpSVL6wAalb2BPelWzwfYvT8n7fQm+TRf78+BlwI3AVTVxcCxTRNplJI8JcmFSb4+99Rakutb59oJeNtbs36fbq7qW5O8DbgA+L3GmaRlMdk7U8Ddquq8ZLNfnm9uFUaj9nrgZ4FLynFxaUmq6i1JPgg8tD/1kqr6astM0nKZ8p2pryW5D/1vz0meDvxb20gaqauAz1qkttuNrQOovST37//5ELp1yK7qP36wPyft9CY7AT3JvYEzgIcD1wFfBJ5VVVc2DabRSXIE8NvAx4FbN/F15WZIsi/dMgm33uWuqk+0S6SxSXJGVZ3Q7803+wNnbo9L9+bTTm9yw3xJTqqqNwD3qqrHJ7k7cKequqF1No3W7wL/SbfW1G6Ns4xGklcBPw9cCtzSny7AMqVbVdUJ/adPAn6J27Zl+iTdQ0DSTm9yd6aSXFRVD/axbS1Wks9W1QNa5xibfmX4w6rqu9u8WJOX5CzgeuCv+1PPBPaqqme0SyUtj8ndmQIuS/IFuvH6i2fOz91yPqxRLo3X2Ul+sqr+sXWQkbkC2JWZoU9pKx5QVYfOHH80yaXN0kjLaHJlqqqOS/IDwDnA0a3zaKfwIuA3knyXbimNueK9Z9tYzX0buCjJh9l8LpkrwmshFyR5WFWdC5DkocD6xpmkZTG5Yb6FJNkb2L9fa0rSImxpZXgXOdWsJJfQzZHaFbgf8OX++EDgc/PuVkk7pcmWqSQfo7sztQtwPvAfwKeq6uSWuTQeSe5fVZ/b0uPbVXXBSmcamyS7AfftDy+vqpta5tH4JDlwa6/7BLXuCKZcpi6sqsOTHE93V+rlSS52zpTmzHuke86t/8FM/ZHuJI8B3gZ8iW7oc3/gOS6NIGlqprxo5y5J7gU8A3h/6zAan5lHuv8UOKaqHgt8FPgm8BvNgo3HHwI/WVWPrqpHAT8FvK5xJklacVMuU6fRTULfWFXr+kU8v9A4k8bpZVV1fZJHAo8D/gLXxwHYtaounzuoqs/TzYuRpEmZ7DCftFgzQ8KvpNuf751z51pnaynJm4HvAX/Vn3oWsKqqnt8ulSStvMmWqSSrgRcCB7H5Vhj+INBmkrwfuBp4AvAQ4L+A86rqQU2DNZbkzsAv061oDd2K1n/iIp6SpmbKZepf6L75n89tW2FQVX/TLJRGKcndgKPo7kp9oZ9r90AX8dy6JH9TVU9rnUOSdrQpl6mLqurBrXNId1QOhUqaiilPQH9/kie1DiHdgU3zNzVJkzPlO1M3AHen2wbDLUKkZeZm4pKmYnJ7882pqj1aZ5Du4NI6gCSthMmWKbh1T75DgLvMnXP1ZmnZvKR1AElaCVMe5jseOAnYD7gIeBjw6alvESIt1swGtrO+CawHfqeqrl35VJK08qY8Af0k4Ajgyn6bkMOBb7SNJO1UPgh8gG6xzmcBf09XpL4KvLVdLElaWVMe5vtOVX0nCUnuXFWfS3K/1qGkncjj500wv2Ru0nmSZzdLJUkrbMplalOSewDvAz6U5DrgysaZpJ3JqiRHVtV5AEmOAFb1r93cLpYkrazJzpmaleTRwF7AP1TVja3zSDuDvjy9Gdid7sm964HjgQ3Ak6vqrIbxJGnFTLJMJVkFbKiq+7fOIu3skuwFUFXfbJ1FklqY5DBfVd2S5PIkB1TVl1vnkXZG/UbHT6PfLDzplpWqqtMaxpKkFTfJMtXbG9iQ5DzgW3Mnq+rodpGkncrf0S2FcD7dTgKSNElTLlN3AZ4ycxzgVY2ySDuj/arqqNYhJKm1KZepXarq47Mnkty1VRhpJ/QvSR5YVZe0DiJJLU2uTCV5EfBLwL2TXDzz0h7Ap9qkknZKjwSem+SLdMN8c5uFH9Y2liStrMk9zdc/ebQ38ErglJmXbqiqr7dJJe18khy40Pmqcr02SZMyuTIlaZgke1bV9Um+b6HX/aVE0tRYpiRtlyTvr6qn9MN7RTe8N6eq6t6NoklSE5YpSZKkASY3AV3S8kmyL3AgM99LquoT7RJJ0sqzTElakiSvAn4euBS4pT9dgGVK0qQ4zCdpSZJcDhxWVa5+LmnS7tQ6gKSd1hXArq1DSFJrDvNJWqpvAxcl+TAze/NV1a+0iyRJK88yJWmp1vYfkjRpzpmStN2SrAL+qaoe2zqLJLXmnClJ262qbgG+12/PJEmT5jCfpKX6T+CSJB8CvjV30jlTkqbGMiVpqf62/5CkSXPOlCRJ0gDemZK0JEkOAV4JHArcZe68Gx1LmhonoEtaqrcAfwrcDDwWeDvwV00TSVIDDvNJWpIk51fVjya5pKoeOHuudTZJWkkO80laqu8muRPwhSQnAlcDuzfOJEkrzjtTkpYkyRHAZcA9gN8G9gReU1XnNg0mSSvMMiVpkCR3q6pvt84hSa04AV3SkiT5sSSXAp/rjx+U5E8ax5KkFWeZkrRUrwd+CrgWoKo+AzyqaSJJasAyJWnJquqqeaduaRJEkhryaT5JS3VVkocDlWRX4CS6CemSNClOQJe0JEn2Ad4APB4I8I/ASVV1bdNgkrTCLFOSJEkDOMwnabskeSOwxd/CqupXVjCOJDVnmZK0vda3DiBJY+Iwn6QdIskbq+rFrXNI0o7m0giSdpRHtA4gSSvBMiVJkjSAZUqSJGkAy5SkHSWtA0jSSrBMSdpuSVYl+YNtXPaGFQkjSY35NJ+kJUlyblU9rHUOSWrNdaYkLdWFSdYC7wG+NXeyqv62XSRJWnmWKUlLdRfgWuBxM+cKsExJmhSH+SRJkgZwArqkJUly3yQfTvLZ/viwJC9rnUuSVpplStJS/TnwUuAmgKq6GDi2aSJJasAyJWmp7lZV5807d3OTJJLUkGVK0lJ9Lcl96Cadk+TpwL+1jSRJK88J6JKWJMm9gTOAhwPXAV8EnlVVVzYNJkkrzKURJG2XJCdV1RuAe1XV45PcHbhTVd3QOpskteCdKUnbJclFVfXgJBdU1UNa55Gk1rwzJWl7XZbkC8APJrl45nyAqqrDGuWSpCa8MyVpuyX5AeAc4Oj5rzlnStLUWKYkDZZkb2D/fq0pSZoUl0aQtCRJPpZkzyTfB1wA/HmS17bOJUkrzTIlaan2qqrrgZ8F3l5VDwUe3ziTJK04y5Skpdolyb2AZwDvbx1GklqxTElaqtPoJqFvrKp1/SKeX2icSZJWnBPQJUmSBnCdKUlLkmQ18ELgIGa+l1TV81tlkqQWLFOSlurvgE8C/wTc0jiLJDXjMJ+kJZnbVqZ1DklqzQnokpbq/Ume1DqEJLXmnSlJS5LkBuDuwHeBm7htb749mwaTpBVmmZIkSRrACeiSlqzfk+8Q4C5z56rqE+0SSdLKs0xJWpIkxwMnAfsBFwEPAz4NPK5lLklaaU5Al7RUJwFHAFdW1WOBw4FvtI0kSSvPMiVpqb5TVd8BSHLnqvoccL/GmSRpxTnMJ2mpNiW5B/A+4ENJrgOubJxJklacT/NJGizJo4G9gH+oqhtb55GklWSZkrTdkqwCNlTV/VtnkaTWnDMlabtV1S3A5UkOaJ1FklpzzpSkpdob2JDkPOBbcyer6uh2kSRp5VmmJC3VXYCnzBwHeFWjLJLUjGVK0lLtUlUfnz2R5K6twkhSK5YpSdslyYuAXwLuneTimZf2AD7VJpUktePTfJK2S5K96OZLvRI4ZealG6rq621SSVI7lilJkqQBXBpBkiRpAMuUJEnSAJYpSZKkASxTkiRJA1imJEmSBvj/Bkqrckt8croAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOVibBZeK5u"
      },
      "source": [
        "### uploading our model training logs to TensorBoard.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP4ZfTBEanGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4372657a-ceef-4a82-c19c-037e625afd17"
      },
      "source": [
        "# we will further inspect our models performance using TensorBoard.dev\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP modelling experiments\" \\\n",
        "  --description \"comparing different types of model architectures on kaggle tweet text classification\" \\\n",
        "  --one_shot # exit the uploader once uploading is finished"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-23 08:18:26.968695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 08:18:26.990369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 08:18:26.991056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=Fx6UWxt3qtXw8Gv6sNErWQXWFxdxLQ&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AX4XfWhUkzgKq68IGl1ZTE7m3KrpK8OdMod9FTAwFZVGCndngwz30svs9Ts\n",
            "\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/c3YadCJQTneX9qoHAdJM8A/\n",
            "\n",
            "\u001b[1m[2021-08-23T08:27:50]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-08-23T08:27:56]\u001b[0m Total uploaded: 210 scalars, 0 tensors, 7 binary objects (3.6 MB)\n",
            "\u001b[1m[2021-08-23T08:27:56]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/c3YadCJQTneX9qoHAdJM8A/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fucpegfclee2"
      },
      "source": [
        "### SAVING AND LOADING A TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWVFgbjmleAS"
      },
      "source": [
        "# save transfer learning model HDF5 format\n",
        "model_6.save('model_6.h5')"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4SWPx4CmXIh"
      },
      "source": [
        "# load model with custom hub layer\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1J16McfnEhw",
        "outputId": "fa8a6463-1de5-4c7d-91c5-0cd63038573f"
      },
      "source": [
        "# how does our loaded model performs\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)\n",
        "# our loaded model evaluates the same."
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 14ms/step - loss: 0.4272 - accuracy: 0.8110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.427209734916687, 0.8110235929489136]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS6SyRZ8nRhv",
        "outputId": "8d280f4d-7f5a-4f5b-a2b1-ba839d7b7389"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To90U_Aonn52"
      },
      "source": [
        "now, let's save to save model format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpvZ4CHnnr4n",
        "outputId": "529150ee-b398-4ede-a4ad-e041fbc62ce7"
      },
      "source": [
        "# save our transfer learning model to SavedModel format (default)\n",
        "model_6.save(\"model_6_savedmodel_format\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_savedmodel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_savedmodel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS0bCUlKoRlX"
      },
      "source": [
        "# load our model from savemodel format\n",
        "loaded_model_6_savedmodel_format = tf.keras.models.load_model(\"model_6_savedmodel_format\") # we don't need to pass custom object in this."
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ACKBjbHouYW",
        "outputId": "fc23d97d-c536-46cf-b41b-2953f7db3748"
      },
      "source": [
        "loaded_model_6_savedmodel_format.evaluate(val_sentences,val_labels)\n",
        "# our loaded model is evaluating the same as our unsaved model."
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 15ms/step - loss: 0.4272 - accuracy: 0.8110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.427209734916687, 0.8110235929489136]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8leMZvEuo0TL",
        "outputId": "ff5eaafa-b5ab-44dd-c70c-c914e8421a31"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndlzImbTpoKR"
      },
      "source": [
        "### FINDING THE MOST WRONG EXAMPLES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYz1zL9bqphR"
      },
      "source": [
        "This is also called model driven data exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFFdeMv8qOVT"
      },
      "source": [
        "for example: if our sample should have label 0, but our model is predicting prediction 1 (prediction probability very close to 1) and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_yvRZQdpvtB",
        "outputId": "9d5d40c6-8f78-4208-ffbb-51021fe007e3"
      },
      "source": [
        "# download a pretrained model from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-23 08:28:26--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.128, 172.217.219.128, 209.85.147.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  40.6MB/s    in 13s     \n",
            "\n",
            "2021-08-23 08:28:40 (69.4 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb6I2ZKerXgm",
        "outputId": "26e67492-f061-4cc0-dced-ea7740cbd392"
      },
      "source": [
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78EdcqmNsLu7",
        "outputId": "c5c6ee10-a60c-43d4-b59e-3611300af9cd"
      },
      "source": [
        "# import previously trained model from google storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxlpwWBtsixb",
        "outputId": "4a3c07b8-c44c-49d7-a88f-073c9d333619"
      },
      "source": [
        "model_6_pretrained.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 14ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5IxjZ7Wsq6p",
        "outputId": "62a89738-da03-49ac-c156-8274e5eb3182"
      },
      "source": [
        "# making predictions with the help of our loaded model\n",
        "model_6_pretrained_pred_prob = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_pred_prob"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.15975739],\n",
              "       [0.747162  ],\n",
              "       [0.98874855],\n",
              "       [0.19622944],\n",
              "       [0.7078078 ],\n",
              "       [0.70967495],\n",
              "       [0.98190695],\n",
              "       [0.9810662 ],\n",
              "       [0.94574374],\n",
              "       [0.08504027],\n",
              "       [0.5865289 ],\n",
              "       [0.5043442 ],\n",
              "       [0.14771107],\n",
              "       [0.47138923],\n",
              "       [0.23241065],\n",
              "       [0.0264297 ],\n",
              "       [0.34196842],\n",
              "       [0.5798138 ],\n",
              "       [0.32017288],\n",
              "       [0.30561873],\n",
              "       [0.91616416],\n",
              "       [0.11672409],\n",
              "       [0.44983855],\n",
              "       [0.0371858 ],\n",
              "       [0.8907019 ],\n",
              "       [0.9726116 ],\n",
              "       [0.06691607],\n",
              "       [0.11293408],\n",
              "       [0.09126016],\n",
              "       [0.31542996],\n",
              "       [0.46357128],\n",
              "       [0.91019577],\n",
              "       [0.42712083],\n",
              "       [0.26243824],\n",
              "       [0.53864133],\n",
              "       [0.08706519],\n",
              "       [0.9805033 ],\n",
              "       [0.0632422 ],\n",
              "       [0.03899793],\n",
              "       [0.98444635],\n",
              "       [0.07138808],\n",
              "       [0.24111237],\n",
              "       [0.40415815],\n",
              "       [0.5092295 ],\n",
              "       [0.23785055],\n",
              "       [0.965647  ],\n",
              "       [0.36541235],\n",
              "       [0.9574007 ],\n",
              "       [0.65664816],\n",
              "       [0.80312175],\n",
              "       [0.06208596],\n",
              "       [0.63057166],\n",
              "       [0.15012795],\n",
              "       [0.05804099],\n",
              "       [0.11978567],\n",
              "       [0.03431042],\n",
              "       [0.09176936],\n",
              "       [0.8867866 ],\n",
              "       [0.11936009],\n",
              "       [0.04963727],\n",
              "       [0.0795938 ],\n",
              "       [0.9742622 ],\n",
              "       [0.96986747],\n",
              "       [0.10175437],\n",
              "       [0.9148204 ],\n",
              "       [0.95497984],\n",
              "       [0.69064474],\n",
              "       [0.17935984],\n",
              "       [0.05485565],\n",
              "       [0.49502054],\n",
              "       [0.10519974],\n",
              "       [0.0781091 ],\n",
              "       [0.7686151 ],\n",
              "       [0.04997266],\n",
              "       [0.03503983],\n",
              "       [0.45674196],\n",
              "       [0.1642501 ],\n",
              "       [0.24587402],\n",
              "       [0.07084261],\n",
              "       [0.711622  ],\n",
              "       [0.71675617],\n",
              "       [0.4933838 ],\n",
              "       [0.9322654 ],\n",
              "       [0.07981516],\n",
              "       [0.6501491 ],\n",
              "       [0.60346246],\n",
              "       [0.07877447],\n",
              "       [0.13202296],\n",
              "       [0.9883526 ],\n",
              "       [0.8943099 ],\n",
              "       [0.9958067 ],\n",
              "       [0.04061905],\n",
              "       [0.08181714],\n",
              "       [0.02564255],\n",
              "       [0.96885306],\n",
              "       [0.72480106],\n",
              "       [0.962187  ],\n",
              "       [0.8598726 ],\n",
              "       [0.9785986 ],\n",
              "       [0.93560225],\n",
              "       [0.9338253 ],\n",
              "       [0.16306615],\n",
              "       [0.18402746],\n",
              "       [0.99038374],\n",
              "       [0.9767081 ],\n",
              "       [0.03517187],\n",
              "       [0.8793165 ],\n",
              "       [0.7670415 ],\n",
              "       [0.14389315],\n",
              "       [0.81083965],\n",
              "       [0.10821024],\n",
              "       [0.05869284],\n",
              "       [0.21471883],\n",
              "       [0.2963578 ],\n",
              "       [0.13797796],\n",
              "       [0.20641874],\n",
              "       [0.41226986],\n",
              "       [0.5630189 ],\n",
              "       [0.7776005 ],\n",
              "       [0.76690084],\n",
              "       [0.92357814],\n",
              "       [0.14835861],\n",
              "       [0.5737875 ],\n",
              "       [0.7906728 ],\n",
              "       [0.5667702 ],\n",
              "       [0.38522986],\n",
              "       [0.16229346],\n",
              "       [0.09369728],\n",
              "       [0.10938514],\n",
              "       [0.28681025],\n",
              "       [0.10985906],\n",
              "       [0.9438952 ],\n",
              "       [0.9585573 ],\n",
              "       [0.9735501 ],\n",
              "       [0.7652836 ],\n",
              "       [0.1825932 ],\n",
              "       [0.95698303],\n",
              "       [0.48600468],\n",
              "       [0.42466977],\n",
              "       [0.15132149],\n",
              "       [0.9758908 ],\n",
              "       [0.11520289],\n",
              "       [0.44988844],\n",
              "       [0.3949142 ],\n",
              "       [0.7626622 ],\n",
              "       [0.38808137],\n",
              "       [0.03667064],\n",
              "       [0.07806098],\n",
              "       [0.1412506 ],\n",
              "       [0.9002287 ],\n",
              "       [0.3492837 ],\n",
              "       [0.06046975],\n",
              "       [0.48483953],\n",
              "       [0.07085565],\n",
              "       [0.386213  ],\n",
              "       [0.77745926],\n",
              "       [0.62789303],\n",
              "       [0.08345093],\n",
              "       [0.9416598 ],\n",
              "       [0.16120158],\n",
              "       [0.8945924 ],\n",
              "       [0.07953541],\n",
              "       [0.16787906],\n",
              "       [0.9424627 ],\n",
              "       [0.06817531],\n",
              "       [0.05040929],\n",
              "       [0.9937172 ],\n",
              "       [0.16884421],\n",
              "       [0.9178595 ],\n",
              "       [0.12875395],\n",
              "       [0.98194444],\n",
              "       [0.39580938],\n",
              "       [0.9577749 ],\n",
              "       [0.06466511],\n",
              "       [0.94553053],\n",
              "       [0.03711996],\n",
              "       [0.8530812 ],\n",
              "       [0.43872583],\n",
              "       [0.54341525],\n",
              "       [0.9946464 ],\n",
              "       [0.05311807],\n",
              "       [0.69247985],\n",
              "       [0.33215526],\n",
              "       [0.8808913 ],\n",
              "       [0.9217177 ],\n",
              "       [0.29192433],\n",
              "       [0.16390365],\n",
              "       [0.97697634],\n",
              "       [0.2682234 ],\n",
              "       [0.08997689],\n",
              "       [0.30184257],\n",
              "       [0.9569481 ],\n",
              "       [0.08252665],\n",
              "       [0.17769651],\n",
              "       [0.10604803],\n",
              "       [0.08798095],\n",
              "       [0.11760179],\n",
              "       [0.18448232],\n",
              "       [0.094571  ],\n",
              "       [0.06215362],\n",
              "       [0.14026356],\n",
              "       [0.95679957],\n",
              "       [0.84415287],\n",
              "       [0.21782668],\n",
              "       [0.13343613],\n",
              "       [0.9855031 ],\n",
              "       [0.23559122],\n",
              "       [0.80476445],\n",
              "       [0.89318436],\n",
              "       [0.8354544 ],\n",
              "       [0.03102637],\n",
              "       [0.9732125 ],\n",
              "       [0.05066632],\n",
              "       [0.09067097],\n",
              "       [0.03366363],\n",
              "       [0.04311363],\n",
              "       [0.88447857],\n",
              "       [0.88327116],\n",
              "       [0.62169623],\n",
              "       [0.0495606 ],\n",
              "       [0.50733656],\n",
              "       [0.05459698],\n",
              "       [0.08636224],\n",
              "       [0.20727086],\n",
              "       [0.9864629 ],\n",
              "       [0.15183406],\n",
              "       [0.19319233],\n",
              "       [0.9693755 ],\n",
              "       [0.6653581 ],\n",
              "       [0.28822708],\n",
              "       [0.78577286],\n",
              "       [0.17246349],\n",
              "       [0.9318369 ],\n",
              "       [0.04208682],\n",
              "       [0.34332052],\n",
              "       [0.47824135],\n",
              "       [0.38159898],\n",
              "       [0.5689484 ],\n",
              "       [0.9801656 ],\n",
              "       [0.03498702],\n",
              "       [0.5577706 ],\n",
              "       [0.26126298],\n",
              "       [0.97766113],\n",
              "       [0.90170264],\n",
              "       [0.03894945],\n",
              "       [0.19816327],\n",
              "       [0.89018375],\n",
              "       [0.15999876],\n",
              "       [0.10654857],\n",
              "       [0.7430262 ],\n",
              "       [0.11445157],\n",
              "       [0.8272134 ],\n",
              "       [0.03217496],\n",
              "       [0.47252864],\n",
              "       [0.88736224],\n",
              "       [0.19847062],\n",
              "       [0.7919484 ],\n",
              "       [0.9927901 ],\n",
              "       [0.38107333],\n",
              "       [0.1071294 ],\n",
              "       [0.9484882 ],\n",
              "       [0.10461501],\n",
              "       [0.18628454],\n",
              "       [0.9569897 ],\n",
              "       [0.855219  ],\n",
              "       [0.6992364 ],\n",
              "       [0.9261521 ],\n",
              "       [0.06630529],\n",
              "       [0.13090213],\n",
              "       [0.08407342],\n",
              "       [0.1256183 ],\n",
              "       [0.40572438],\n",
              "       [0.91705877],\n",
              "       [0.10228746],\n",
              "       [0.30739534],\n",
              "       [0.9308319 ],\n",
              "       [0.12316016],\n",
              "       [0.07916722],\n",
              "       [0.97953326],\n",
              "       [0.4410636 ],\n",
              "       [0.08928312],\n",
              "       [0.14628577],\n",
              "       [0.9627774 ],\n",
              "       [0.3694937 ],\n",
              "       [0.20825642],\n",
              "       [0.53840846],\n",
              "       [0.7697408 ],\n",
              "       [0.15494674],\n",
              "       [0.7604925 ],\n",
              "       [0.05109562],\n",
              "       [0.7559236 ],\n",
              "       [0.5744491 ],\n",
              "       [0.29451203],\n",
              "       [0.6898008 ],\n",
              "       [0.05460339],\n",
              "       [0.87279797],\n",
              "       [0.23014756],\n",
              "       [0.9764405 ],\n",
              "       [0.07265326],\n",
              "       [0.5257345 ],\n",
              "       [0.3572394 ],\n",
              "       [0.08900195],\n",
              "       [0.06277464],\n",
              "       [0.6949764 ],\n",
              "       [0.23097585],\n",
              "       [0.14382918],\n",
              "       [0.09234572],\n",
              "       [0.7117387 ],\n",
              "       [0.05370635],\n",
              "       [0.02875542],\n",
              "       [0.10861149],\n",
              "       [0.9677088 ],\n",
              "       [0.66516674],\n",
              "       [0.20455061],\n",
              "       [0.9747645 ],\n",
              "       [0.06717411],\n",
              "       [0.9091663 ],\n",
              "       [0.63377154],\n",
              "       [0.02835695],\n",
              "       [0.22207233],\n",
              "       [0.09472778],\n",
              "       [0.13411398],\n",
              "       [0.9766287 ],\n",
              "       [0.06805696],\n",
              "       [0.67504233],\n",
              "       [0.06511179],\n",
              "       [0.20027284],\n",
              "       [0.8487042 ],\n",
              "       [0.06048408],\n",
              "       [0.8230663 ],\n",
              "       [0.8522237 ],\n",
              "       [0.09048881],\n",
              "       [0.9214631 ],\n",
              "       [0.24200875],\n",
              "       [0.1736149 ],\n",
              "       [0.4927854 ],\n",
              "       [0.05024087],\n",
              "       [0.37760377],\n",
              "       [0.5275739 ],\n",
              "       [0.5186966 ],\n",
              "       [0.11100341],\n",
              "       [0.16210093],\n",
              "       [0.9208815 ],\n",
              "       [0.9630833 ],\n",
              "       [0.7666251 ],\n",
              "       [0.18886812],\n",
              "       [0.2853009 ],\n",
              "       [0.08490452],\n",
              "       [0.05668304],\n",
              "       [0.15824904],\n",
              "       [0.20558488],\n",
              "       [0.38218814],\n",
              "       [0.07125733],\n",
              "       [0.08729415],\n",
              "       [0.54148823],\n",
              "       [0.03899122],\n",
              "       [0.9642405 ],\n",
              "       [0.96544605],\n",
              "       [0.8217793 ],\n",
              "       [0.656186  ],\n",
              "       [0.39739808],\n",
              "       [0.07898201],\n",
              "       [0.9523582 ],\n",
              "       [0.5120969 ],\n",
              "       [0.3345523 ],\n",
              "       [0.04445301],\n",
              "       [0.15117636],\n",
              "       [0.07661173],\n",
              "       [0.15448494],\n",
              "       [0.025258  ],\n",
              "       [0.74500877],\n",
              "       [0.04204529],\n",
              "       [0.13965218],\n",
              "       [0.21822315],\n",
              "       [0.07040995],\n",
              "       [0.07515307],\n",
              "       [0.10678563],\n",
              "       [0.15834108],\n",
              "       [0.13357948],\n",
              "       [0.37615386],\n",
              "       [0.9437928 ],\n",
              "       [0.7472231 ],\n",
              "       [0.10133481],\n",
              "       [0.23488288],\n",
              "       [0.5279857 ],\n",
              "       [0.96022993],\n",
              "       [0.3712227 ],\n",
              "       [0.301807  ],\n",
              "       [0.99093187],\n",
              "       [0.22258466],\n",
              "       [0.11191651],\n",
              "       [0.40047908],\n",
              "       [0.04157007],\n",
              "       [0.8148158 ],\n",
              "       [0.70884573],\n",
              "       [0.9918819 ],\n",
              "       [0.10798524],\n",
              "       [0.73808014],\n",
              "       [0.25972372],\n",
              "       [0.31906572],\n",
              "       [0.96187973],\n",
              "       [0.14267415],\n",
              "       [0.6304137 ],\n",
              "       [0.90205777],\n",
              "       [0.09132845],\n",
              "       [0.94973105],\n",
              "       [0.27648488],\n",
              "       [0.7162835 ],\n",
              "       [0.05507582],\n",
              "       [0.28721857],\n",
              "       [0.84635305],\n",
              "       [0.04391849],\n",
              "       [0.08296154],\n",
              "       [0.54169154],\n",
              "       [0.9379428 ],\n",
              "       [0.75744766],\n",
              "       [0.27196032],\n",
              "       [0.9609165 ],\n",
              "       [0.20435852],\n",
              "       [0.08181331],\n",
              "       [0.9635671 ],\n",
              "       [0.86571664],\n",
              "       [0.6750452 ],\n",
              "       [0.76839274],\n",
              "       [0.03299075],\n",
              "       [0.5799661 ],\n",
              "       [0.12719817],\n",
              "       [0.8242215 ],\n",
              "       [0.5115376 ],\n",
              "       [0.92087525],\n",
              "       [0.0748279 ],\n",
              "       [0.05833485],\n",
              "       [0.11161529],\n",
              "       [0.6268863 ],\n",
              "       [0.22306482],\n",
              "       [0.2523592 ],\n",
              "       [0.47445032],\n",
              "       [0.33258408],\n",
              "       [0.9863886 ],\n",
              "       [0.6890807 ],\n",
              "       [0.6044843 ],\n",
              "       [0.72704864],\n",
              "       [0.33945   ],\n",
              "       [0.13527158],\n",
              "       [0.19235983],\n",
              "       [0.7270074 ],\n",
              "       [0.05705645],\n",
              "       [0.05114507],\n",
              "       [0.195404  ],\n",
              "       [0.18774334],\n",
              "       [0.04116558],\n",
              "       [0.886097  ],\n",
              "       [0.9306086 ],\n",
              "       [0.8421794 ],\n",
              "       [0.961171  ],\n",
              "       [0.9819733 ],\n",
              "       [0.06695292],\n",
              "       [0.22556007],\n",
              "       [0.37276503],\n",
              "       [0.85715103],\n",
              "       [0.9854494 ],\n",
              "       [0.05768617],\n",
              "       [0.11720087],\n",
              "       [0.3820634 ],\n",
              "       [0.99035406],\n",
              "       [0.9485411 ],\n",
              "       [0.17405894],\n",
              "       [0.19845526],\n",
              "       [0.90119994],\n",
              "       [0.03148602],\n",
              "       [0.15139852],\n",
              "       [0.9265263 ],\n",
              "       [0.55706996],\n",
              "       [0.29339424],\n",
              "       [0.6880071 ],\n",
              "       [0.491344  ],\n",
              "       [0.83585626],\n",
              "       [0.9767313 ],\n",
              "       [0.0807341 ],\n",
              "       [0.05128007],\n",
              "       [0.15175132],\n",
              "       [0.05791806],\n",
              "       [0.31966084],\n",
              "       [0.84931785],\n",
              "       [0.03935684],\n",
              "       [0.62032926],\n",
              "       [0.08042652],\n",
              "       [0.08053841],\n",
              "       [0.2733795 ],\n",
              "       [0.45661315],\n",
              "       [0.34159246],\n",
              "       [0.96383256],\n",
              "       [0.18058416],\n",
              "       [0.08693017],\n",
              "       [0.10112957],\n",
              "       [0.13359444],\n",
              "       [0.5095021 ],\n",
              "       [0.79077786],\n",
              "       [0.11439804],\n",
              "       [0.878574  ],\n",
              "       [0.9595846 ],\n",
              "       [0.04478138],\n",
              "       [0.36174008],\n",
              "       [0.7679462 ],\n",
              "       [0.1999613 ],\n",
              "       [0.68779194],\n",
              "       [0.09078656],\n",
              "       [0.94784397],\n",
              "       [0.2063842 ],\n",
              "       [0.19149646],\n",
              "       [0.13619559],\n",
              "       [0.06194349],\n",
              "       [0.17514493],\n",
              "       [0.6590747 ],\n",
              "       [0.9500922 ],\n",
              "       [0.15297005],\n",
              "       [0.97554487],\n",
              "       [0.6160707 ],\n",
              "       [0.6006812 ],\n",
              "       [0.9830496 ],\n",
              "       [0.41101813],\n",
              "       [0.37341127],\n",
              "       [0.8167042 ],\n",
              "       [0.9546811 ],\n",
              "       [0.04997934],\n",
              "       [0.17845918],\n",
              "       [0.06888239],\n",
              "       [0.20932107],\n",
              "       [0.34605378],\n",
              "       [0.92120403],\n",
              "       [0.7170678 ],\n",
              "       [0.9599156 ],\n",
              "       [0.07546329],\n",
              "       [0.03697741],\n",
              "       [0.81180984],\n",
              "       [0.09887671],\n",
              "       [0.06730346],\n",
              "       [0.05370319],\n",
              "       [0.11762222],\n",
              "       [0.38447213],\n",
              "       [0.18544427],\n",
              "       [0.49785644],\n",
              "       [0.2171641 ],\n",
              "       [0.14417706],\n",
              "       [0.1129555 ],\n",
              "       [0.18098459],\n",
              "       [0.3507185 ],\n",
              "       [0.94636106],\n",
              "       [0.77714074],\n",
              "       [0.71625304],\n",
              "       [0.9200865 ],\n",
              "       [0.94156563],\n",
              "       [0.05650314],\n",
              "       [0.82954484],\n",
              "       [0.06633511],\n",
              "       [0.9796361 ],\n",
              "       [0.06334137],\n",
              "       [0.17317028],\n",
              "       [0.23175472],\n",
              "       [0.0478004 ],\n",
              "       [0.14770743],\n",
              "       [0.24318844],\n",
              "       [0.93399644],\n",
              "       [0.8602127 ],\n",
              "       [0.81021166],\n",
              "       [0.07506065],\n",
              "       [0.7439609 ],\n",
              "       [0.71225935],\n",
              "       [0.0837395 ],\n",
              "       [0.21536836],\n",
              "       [0.8368754 ],\n",
              "       [0.64447135],\n",
              "       [0.9818209 ],\n",
              "       [0.24812761],\n",
              "       [0.12154759],\n",
              "       [0.5518035 ],\n",
              "       [0.10715658],\n",
              "       [0.7356607 ],\n",
              "       [0.90649444],\n",
              "       [0.21228719],\n",
              "       [0.06237458],\n",
              "       [0.07125255],\n",
              "       [0.9524399 ],\n",
              "       [0.16770287],\n",
              "       [0.05825526],\n",
              "       [0.96736574],\n",
              "       [0.17010686],\n",
              "       [0.08471746],\n",
              "       [0.6918948 ],\n",
              "       [0.02399373],\n",
              "       [0.24603532],\n",
              "       [0.34795064],\n",
              "       [0.5652417 ],\n",
              "       [0.01289633],\n",
              "       [0.24597432],\n",
              "       [0.9370736 ],\n",
              "       [0.11521666],\n",
              "       [0.9229592 ],\n",
              "       [0.9846817 ],\n",
              "       [0.05870311],\n",
              "       [0.05885286],\n",
              "       [0.05571281],\n",
              "       [0.9459308 ],\n",
              "       [0.55820686],\n",
              "       [0.9804047 ],\n",
              "       [0.0995947 ],\n",
              "       [0.27878675],\n",
              "       [0.09553558],\n",
              "       [0.05349295],\n",
              "       [0.8022858 ],\n",
              "       [0.11168226],\n",
              "       [0.9353907 ],\n",
              "       [0.08227029],\n",
              "       [0.17333497],\n",
              "       [0.97897494],\n",
              "       [0.2367269 ],\n",
              "       [0.06194216],\n",
              "       [0.38472384],\n",
              "       [0.04903095],\n",
              "       [0.5735117 ],\n",
              "       [0.9852821 ],\n",
              "       [0.07110982],\n",
              "       [0.98388636],\n",
              "       [0.21410635],\n",
              "       [0.8349167 ],\n",
              "       [0.15035647],\n",
              "       [0.4189407 ],\n",
              "       [0.26033485],\n",
              "       [0.85230005],\n",
              "       [0.03249884],\n",
              "       [0.4227665 ],\n",
              "       [0.9333099 ],\n",
              "       [0.68748915],\n",
              "       [0.71266955],\n",
              "       [0.9062496 ],\n",
              "       [0.05026506],\n",
              "       [0.7239137 ],\n",
              "       [0.10267455],\n",
              "       [0.6965426 ],\n",
              "       [0.16762024],\n",
              "       [0.9341144 ],\n",
              "       [0.38917953],\n",
              "       [0.5900947 ],\n",
              "       [0.22254974],\n",
              "       [0.06512338],\n",
              "       [0.6571958 ],\n",
              "       [0.13254407],\n",
              "       [0.18096404],\n",
              "       [0.5725359 ],\n",
              "       [0.96617615],\n",
              "       [0.990141  ],\n",
              "       [0.07760815],\n",
              "       [0.0593347 ],\n",
              "       [0.07835559],\n",
              "       [0.12121762],\n",
              "       [0.2313775 ],\n",
              "       [0.07096054],\n",
              "       [0.9731367 ],\n",
              "       [0.11218104],\n",
              "       [0.49255252],\n",
              "       [0.10464592],\n",
              "       [0.1151934 ],\n",
              "       [0.84137535],\n",
              "       [0.1160218 ],\n",
              "       [0.07808764],\n",
              "       [0.2551088 ],\n",
              "       [0.08823089],\n",
              "       [0.4347857 ],\n",
              "       [0.9813322 ],\n",
              "       [0.51764417],\n",
              "       [0.04499174],\n",
              "       [0.18582225],\n",
              "       [0.13926859],\n",
              "       [0.03826476],\n",
              "       [0.93246895],\n",
              "       [0.19702382],\n",
              "       [0.61172754],\n",
              "       [0.41068435],\n",
              "       [0.1007003 ],\n",
              "       [0.37497738],\n",
              "       [0.26928058],\n",
              "       [0.06967138],\n",
              "       [0.15141033],\n",
              "       [0.84666103],\n",
              "       [0.13634142],\n",
              "       [0.9245858 ],\n",
              "       [0.06000794],\n",
              "       [0.16570723],\n",
              "       [0.20932105],\n",
              "       [0.0378556 ],\n",
              "       [0.8334567 ],\n",
              "       [0.95713186],\n",
              "       [0.2332333 ],\n",
              "       [0.07334226],\n",
              "       [0.9767001 ],\n",
              "       [0.739997  ],\n",
              "       [0.8668527 ],\n",
              "       [0.60979474],\n",
              "       [0.7424103 ],\n",
              "       [0.08628038],\n",
              "       [0.1597724 ],\n",
              "       [0.24860427],\n",
              "       [0.8339873 ],\n",
              "       [0.08106229],\n",
              "       [0.39198714],\n",
              "       [0.20097575],\n",
              "       [0.30522448],\n",
              "       [0.06599221],\n",
              "       [0.07476973],\n",
              "       [0.11885571],\n",
              "       [0.21853667],\n",
              "       [0.1998029 ],\n",
              "       [0.5202779 ],\n",
              "       [0.02045458],\n",
              "       [0.0896696 ],\n",
              "       [0.18554509],\n",
              "       [0.2485142 ],\n",
              "       [0.02252896],\n",
              "       [0.6449204 ],\n",
              "       [0.03482959],\n",
              "       [0.56836027],\n",
              "       [0.14223182],\n",
              "       [0.1727502 ],\n",
              "       [0.8839072 ],\n",
              "       [0.07105079],\n",
              "       [0.31762147],\n",
              "       [0.11430398],\n",
              "       [0.07250895],\n",
              "       [0.94625604],\n",
              "       [0.23219724],\n",
              "       [0.16517283],\n",
              "       [0.86765975],\n",
              "       [0.9417482 ],\n",
              "       [0.8837239 ],\n",
              "       [0.99110985],\n",
              "       [0.9658734 ],\n",
              "       [0.1762422 ],\n",
              "       [0.15820983],\n",
              "       [0.05798144],\n",
              "       [0.7142587 ],\n",
              "       [0.8770503 ],\n",
              "       [0.5628425 ],\n",
              "       [0.40168345],\n",
              "       [0.06153667],\n",
              "       [0.34354165],\n",
              "       [0.38723457],\n",
              "       [0.1121768 ],\n",
              "       [0.19458586],\n",
              "       [0.11751401],\n",
              "       [0.0736684 ],\n",
              "       [0.11800873],\n",
              "       [0.36463296],\n",
              "       [0.9319252 ],\n",
              "       [0.07851925],\n",
              "       [0.9305162 ],\n",
              "       [0.6381151 ],\n",
              "       [0.06289501],\n",
              "       [0.13707368],\n",
              "       [0.09586485],\n",
              "       [0.87698215],\n",
              "       [0.612631  ],\n",
              "       [0.11799197]], dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZEqyh80tF3f",
        "outputId": "713ef868-2664-4fe3-aaed-26ef868ea59f"
      },
      "source": [
        "# converting our prediction probabilities into labels\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_prob))\n",
        "model_6_pretrained_preds"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UJ-Ar-tAt45X",
        "outputId": "80ed9f14-a908-483e-dd4d-74574721bedc"
      },
      "source": [
        "# create a dataframe with our validation_sentences, validation labels, best performing model prediction labels + probabilities\n",
        "\n",
        "val_df = pd.DataFrame({\n",
        "    \"text\":val_sentences,\n",
        "    \"target\":val_labels,\n",
        "    \"pred\": model_6_pretrained_preds,\n",
        "    \"pred_prob\": tf.squeeze(model_6_pretrained_pred_prob)\n",
        "})\n",
        "\n",
        "val_df.head()\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XH2bvsIvUVz"
      },
      "source": [
        "# find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df['target'] != val_df['pred']].sort_values('pred_prob', ascending=False)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lyEljogOv2pg",
        "outputId": "2fec932a-74ad-4683-f6e6-eeabfc5aba15"
      },
      "source": [
        "most_wrong.head(10) # these are false positives"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6vtKF7QMwO7D",
        "outputId": "3caee5fe-9271-4fef-d742-0283149c6ea4"
      },
      "source": [
        "most_wrong.tail(10) # these are false negatives"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>@DavidVonderhaar At least you were sincere ??</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.067303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>Lucas Duda is Ghost Rider. Not the Nic Cage ve...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>going to redo my nails and watch behind the sc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>You can never escape me. Bullets don't harm me...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "536      @DavidVonderhaar At least you were sincere ??       1   0.0   0.067303\n",
              "408  @willienelson We need help! Horses will die!Pl...       1   0.0   0.055076\n",
              "294  Lucas Duda is Ghost Rider. Not the Nic Cage ve...       1   0.0   0.054603\n",
              "221  going to redo my nails and watch behind the sc...       1   0.0   0.054597\n",
              "59   You can never escape me. Bullets don't harm me...       1   0.0   0.049637\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_DL3tGygqZ"
      },
      "source": [
        "let's remind ourselves of labels\n",
        "\n",
        "0: `disaster`\n",
        "\n",
        "1: `not disaster`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJhjEvvDwzSM",
        "outputId": "b8adb568-728c-4286-a6dc-abf9bd045b3d"
      },
      "source": [
        "# check the false positives (model predicted 1 when should have been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target : {target}, pred : {pred}, prediction_probabilities : {pred_prob}\")\n",
        "  print(f\"Text: \\n{text}\\n\")\n",
        "  print(\"----------------------\\n\")\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target : 0, pred : 1.0, prediction_probabilities : 0.9101957678794861\n",
            "Text: \n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8769821524620056\n",
            "Text: \n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8523000478744507\n",
            "Text: \n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8354544043540955\n",
            "Text: \n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8272134065628052\n",
            "Text: \n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8148158192634583\n",
            "Text: \n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8108396530151367\n",
            "Text: \n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.8031217455863953\n",
            "Text: \n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.7669008374214172\n",
            "Text: \n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 0, pred : 1.0, prediction_probabilities : 0.7666251063346863\n",
            "Text: \n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2gWNrHizLIg",
        "outputId": "56355b1c-490f-4f2a-ea63-a80eb5304804"
      },
      "source": [
        "# check the false negatives (model predicted 0 when should have been 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target : {target}, pred : {pred}, prediction_probabilities : {pred_prob}\")\n",
        "  print(f\"Text: \\n{text}\\n\")\n",
        "  print(\"----------------------\\n\")\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target : 1, pred : 0.0, prediction_probabilities : 0.06730346381664276\n",
            "Text: \n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.05507582053542137\n",
            "Text: \n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.05460338667035103\n",
            "Text: \n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.05459698289632797\n",
            "Text: \n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.04963727295398712\n",
            "Text: \n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.043918490409851074\n",
            "Text: \n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.04208682104945183\n",
            "Text: \n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.03899792954325676\n",
            "Text: \n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.038949452340602875\n",
            "Text: \n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----------------------\n",
            "\n",
            "Target : 1, pred : 0.0, prediction_probabilities : 0.037185799330472946\n",
            "Text: \n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuhcvqOY13tJ"
      },
      "source": [
        "### MAKING PREDICITION ON THE TEST DATASET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdKCXOsIztNl",
        "outputId": "d30c3a34-bdcf-4dfa-f77f-55bea5f7eca3"
      },
      "source": [
        "# making prediction on the test dataset and visualizing them\n",
        "test_sentences = test_df['text'].to_list()\n",
        "test_sentences[:10]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Just happened a terrible car crash',\n",
              " 'Heard about #earthquake is different cities, stay safe everyone.',\n",
              " 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
              " 'Apocalypse lighting. #Spokane #wildfires',\n",
              " 'Typhoon Soudelor kills 28 in China and Taiwan',\n",
              " \"We're shaking...It's an earthquake\",\n",
              " \"They'd probably still show more life than Arsenal did yesterday, eh? EH?\",\n",
              " 'Hey! How are you?',\n",
              " 'What a nice hat?',\n",
              " 'Fuck off!']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcd6RRIQGpta",
        "outputId": "016b7ded-2eb0-4c6e-884b-4a4b35f8e72e"
      },
      "source": [
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred : {pred}, Prediction probability : {pred_prob}\")\n",
        "  print(f\"Text : \\n{test_sample}\\n\")\n",
        "  print(\"---------\\n\")"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred : 0.0, Prediction probability : 0.1867247074842453\n",
            "Text : \n",
            "MY DOG JUST FARTED EVACUATE THIS FUCKIN ROOM DISGUSTING ASS BROOM LOOKIN ASS\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.08326753228902817\n",
            "Text : \n",
            "I ain't a crip or a blood....I'm doin my own thing\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 1.0, Prediction probability : 0.8531842231750488\n",
            "Text : \n",
            "Learning from the Legacy of a Catastrophic Eruption - The New Yorker http://t.co/y8YqPBE4t9\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.28575512766838074\n",
            "Text : \n",
            "The footage of Albert Reynolds talking about a hijacker demanding the publication of the 3rd secret of Fatima is hilarious.\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.0461258739233017\n",
            "Text : \n",
            "I checked in at Blazing Horse Tattoo on #Yelp http://t.co/z8nXWmYMWA\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.19680626690387726\n",
            "Text : \n",
            "@dolphfan36 I made it...Didnt drown\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 1.0, Prediction probability : 0.9495252370834351\n",
            "Text : \n",
            "VIDEO: 'We're picking up bodies from water': Rescuers are searching for hundreds of migrants in the Mediterran... http://t.co/XfS3pJhFh9\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.11886700242757797\n",
            "Text : \n",
            "RMT is playing Jackson Browne - Before the Deluge [Listeners: 2/100] [Requests are: On]\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 0.0, Prediction probability : 0.08720804750919342\n",
            "Text : \n",
            "That new sirens and sailors ???? #workout #album\n",
            "\n",
            "---------\n",
            "\n",
            "Pred : 1.0, Prediction probability : 0.9767429232597351\n",
            "Text : \n",
            "Myanmar Flood Victims Need More Relief Aid and Food: Regions struggle with flood aftermath and dwindling suppl... http://t.co/O5adXdNnII\n",
            "\n",
            "---------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpD3VLpyI6hq",
        "outputId": "f34db444-2a8c-4944-bc60-1999b304d778"
      },
      "source": [
        "# predicting on one of my own tweet\n",
        "\n",
        "my_tweet = \"So you'll further remain silent on hindu genocides of kashmir and bengal?\"\n",
        "\n",
        "pred_prob = tf.squeeze(model_6_pretrained.predict([my_tweet]))\n",
        "pred = tf.round(pred_prob)\n",
        "if pred==0:\n",
        "  print('tweet is not indicating any kind of disaster')\n",
        "else:\n",
        "  print('tweet indicates there has been a disaster')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweet indicates there has been a disaster\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WpCLeluLpmz"
      },
      "source": [
        "### THE SPEED/SCORE TRADEOFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajj8kZqKKDWL",
        "outputId": "50a522a0-6fb5-4e2b-91cc-a92ee0b7a496"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nZH6qhSLyAK",
        "outputId": "6b48f5b9-c79b-4980-96a2-3df1bdb2f689"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1-score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S_2jO0YL2WW"
      },
      "source": [
        "our transfer learning model out performed our baseline model with Naive Bayes classifier, but at what cost? it is the cost of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97MshxavMbJV"
      },
      "source": [
        "let's make a function to measure the time of our prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBE6zVM1Ng89"
      },
      "source": [
        "note - perf_counter() function always returns the float value of time in seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C08L70c4MZn_"
      },
      "source": [
        "import time\n",
        "def pred_time(model, sample):\n",
        "  \"\"\"\n",
        "  This function will take a sample and then make a prediction over it and return the time it took\n",
        "  to make the prediction over that sample.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter()\n",
        "  model.predict(sample)\n",
        "  end_time = time.perf_counter()\n",
        "  total_time = end_time - start_time\n",
        "  time_per_prediction = total_time/len(sample)\n",
        "  return total_time, time_per_prediction"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLtZNP3KNF35",
        "outputId": "0a004c3a-b7ed-407f-c283-f42fd4a4d75c"
      },
      "source": [
        "model_6_total_pred_time, model_6_time_per_pred = pred_time(model_6_pretrained, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.34179865800024345, 0.00044855466929165805)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EPkMQlqO8-l",
        "outputId": "0d4727ff-bf7b-4ce8-a142-aaa3b43b8181"
      },
      "source": [
        "# calculating our baseline model prediction time\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_time(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.025437499999952706, 3.338254593169646e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E43ZhOCPvUb",
        "outputId": "ef52775d-730b-48db-e919-3697dce8f566"
      },
      "source": [
        "model_6_pretrained_results = calculate_score(val_labels,model_6_preds)\n",
        "model_6_pretrained_results"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.10236220472441,\n",
              " 'f1-score': 0.8103850144931918,\n",
              " 'precision': 0.8111174658494981,\n",
              " 'recall': 0.8110236220472441}"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "veliIb4nQFAj",
        "outputId": "c6e2a33c-4f13-4665-ce55-bbd4c22246a8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results['f1-score'], label='baseline')\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results['f1-score'], label='tf-hub-sentence-encoder')\n",
        "plt.legend()\n",
        "plt.title(\"f1-score verses time-per-prediction\")\n",
        "plt.xlabel('time per prediction')\n",
        "plt.ylabel('f1-score')\n",
        "plt.show()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}